{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/wandb/edu/blob/main/model-registry-201/Logging_Models_PyTorch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>\n",
    "<!--- @wandbcode{modelreg201-pytorch-colab} -->"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://wandb.me/logo-im-png\" width=\"400\" alt=\"Weights & Biases\" />\n",
    "\n",
    "<!--- @wandbcode{wandb201-pytorch-lightning-colab} -->\n",
    "\n",
    "## Model Registry Tutorial\n",
    "The model registry is a central place to house and organize all the model tasks and their associated artifacts being worked on across an org:\n",
    "- Model checkpoint management\n",
    "- Document your models with rich model cards\n",
    "- Maintain a history of all the models being used/deployed\n",
    "- Facilitate clean hand-offs and stage management of models\n",
    "- Tag and organize various model tasks\n",
    "- Set up automatic notifications when models progress\n",
    "\n",
    "This tutorial will walkthrough how to track the model development lifecycle for a simple image classification task.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 🛠️ Install `wandb`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q wandb onnx pytorch-lightning"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Login to W&B\n",
    "- You can explicitly login using `wandb login` or `wandb.login()` (See below)\n",
    "- Alternatively you can set environment variables. There are several env variables which you can set to change the behavior of W&B logging. The most important are:\n",
    "    - `WANDB_API_KEY` - find this in your \"Settings\" section under your profile\n",
    "    - `WANDB_BASE_URL` - this is the url of the W&B server\n",
    "- Find your API Token in \"Profile\" -> \"Setttings\" in the W&B App\n",
    "\n",
    "![api_token](https://drive.google.com/uc?export=view&id=1Xn7hnn0rfPu_EW0A_-32oCXqDmpA0-kx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb\n",
    "wandb.login()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Log Data and Model Checkpoints as Artifacts  \n",
    "W&B Artifacts allows you to track and version arbitrary serialized data (e.g. datasets, model checkpoints, evaluation results). When you create an artifact, you give it a name and a type, and that artifact is forever linked to the experimental system of record. If the underlying data changes, and you log that data asset again, W&B will automatically create new versions through checksummming its contents. W&B Artifacts can be thought of as a lightweight abstraction layer on top of shared unstructured file systems.\n",
    "\n",
    "### Anatomy of an artifact\n",
    "\n",
    "The `Artifact` class will correspond to an entry in the W&B Artifact registry.  The artifact has\n",
    "* a name\n",
    "* a type\n",
    "* metadata\n",
    "* description\n",
    "* files, directory of files, or references\n",
    "\n",
    "Example usage:\n",
    "```\n",
    "run = wandb.init(project = \"my-project\")\n",
    "artifact = wandb.Artifact(name = \"my_artifact\", type = \"data\")\n",
    "artifact.add_file(\"/path/to/my/file.txt\")\n",
    "run.log_artifact(artifact)\n",
    "run.finish()\n",
    "```\n",
    "\n",
    "In this tutorial, the first thing we will do is download a training dataset and log it as an artifact to be used downstream in the training job."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Enter your W&B project and entity\n",
    "\n",
    "# FORM VARIABLES\n",
    "PROJECT_NAME = \"model-registry-201\" #@param {type:\"string\"}\n",
    "ENTITY = \"wandb\"#@param {type:\"string\"}\n",
    "\n",
    "src_url = \"https://storage.googleapis.com/wandb_datasets/nature_100.zip\"\n",
    "src_zip = \"nature_100.zip\"\n",
    "DATA_SRC = \"nature_100\"\n",
    "IMAGES_PER_LABEL = 10\n",
    "BALANCED_SPLITS = {\"train\" : 8, \"val\" : 1, \"test\": 1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "!curl -SL $src_url > $src_zip\n",
    "!unzip $src_zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "with wandb.init(project=PROJECT_NAME, entity=ENTITY, job_type='log_datasets') as run:\n",
    "  img_paths = []\n",
    "  for root, dirs, files in os.walk('nature_100', topdown=False):\n",
    "    for name in files:\n",
    "        img_path = os.path.join(root, name)\n",
    "        label = img_path.split('/')[1]\n",
    "        img_paths.append([img_path, label])\n",
    "\n",
    "  index_df = pd.DataFrame(columns=['image_path', 'label'], data=img_paths)\n",
    "  index_df.to_csv('index.csv', index=False)\n",
    "\n",
    "  train_art = wandb.Artifact(name='Nature_100', type='raw_images', description='nature image dataset with 10 classes, 10 images per class')\n",
    "  train_art.add_dir('nature_100')\n",
    "\n",
    "  # Also adding a csv indicating the labels of each image\n",
    "  train_art.add_file('index.csv')\n",
    "  wandb.log_artifact(train_art)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Artifact names and aliases to easily hand-off and abstract data assets\n",
    "- By simply referring to the `name:alias` combination of a dataset or model, we can better standardize components of a workflow\n",
    "- For instance, you can build PyTorch `Dataset`'s or `DataModule`'s which take as arguments W&B Artifact names and aliases to load appropriately\n",
    "\n",
    "You can now see all the metadata associated with this dataset, the W&B runs consuming it, and the whole lineage of upstream and downstream artifacts!\n",
    "\n",
    "![api_token](https://drive.google.com/uc?export=view&id=1fEEddXMkabgcgusja0g8zMz8whlP2Y5P)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import transforms\n",
    "import pytorch_lightning as pl\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from skimage import io, transform\n",
    "from torchvision import transforms, utils, models\n",
    "import math\n",
    "\n",
    "class NatureDataset(Dataset):\n",
    "    def __init__(self,\n",
    "                 wandb_run,\n",
    "                 artifact_name_alias=\"Nature_100:latest\",\n",
    "                 local_target_dir=\"Nature_100:latest\",\n",
    "                 transform=None):\n",
    "        self.local_target_dir = local_target_dir\n",
    "        self.transform = transform\n",
    "\n",
    "        # Pull down the artifact locally to load it into memory\n",
    "        art = wandb_run.use_artifact(artifact_name_alias)\n",
    "        path_at = art.download(root=self.local_target_dir)\n",
    "\n",
    "        self.ref_df = pd.read_csv(os.path.join(self.local_target_dir, 'index.csv'))\n",
    "        self.class_names = self.ref_df.iloc[:, 1].unique().tolist()\n",
    "        self.idx_to_class = {k: v for k, v in enumerate(self.class_names)}\n",
    "        self.class_to_idx = {v: k for k, v in enumerate(self.class_names)}\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.ref_df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "\n",
    "        img_path = self.ref_df.iloc[idx, 0]\n",
    "\n",
    "        image = io.imread(img_path)\n",
    "        label = self.ref_df.iloc[idx, 1]\n",
    "        label = torch.tensor(self.class_to_idx[label], dtype=torch.long)\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, label\n",
    "\n",
    "\n",
    "class NatureDatasetModule(pl.LightningDataModule):\n",
    "    def __init__(self,\n",
    "                 wandb_run,\n",
    "                 artifact_name_alias: str = \"Nature_100:latest\",\n",
    "                 local_target_dir: str = \"Nature_100:latest\",\n",
    "                 batch_size: int = 16,\n",
    "                 input_size: int = 224,\n",
    "                 seed: int = 42):\n",
    "        super().__init__()\n",
    "        self.wandb_run = wandb_run\n",
    "        self.artifact_name_alias = artifact_name_alias\n",
    "        self.local_target_dir = local_target_dir\n",
    "        self.batch_size = batch_size\n",
    "        self.input_size = input_size\n",
    "        self.seed = seed\n",
    "\n",
    "    def setup(self, stage=None):\n",
    "        self.nature_dataset = NatureDataset(wandb_run=self.wandb_run,\n",
    "                                            artifact_name_alias=self.artifact_name_alias,\n",
    "                                            local_target_dir=self.local_target_dir,\n",
    "                                            transform=transforms.Compose([transforms.ToTensor(),\n",
    "                                                                          transforms.CenterCrop(self.input_size),\n",
    "                                                                          transforms.Normalize((0.485, 0.456, 0.406),\n",
    "                                                                                               (0.229, 0.224, 0.225))]))\n",
    "\n",
    "        nature_length = len(self.nature_dataset)\n",
    "        train_size = math.floor(0.8 * nature_length)\n",
    "        val_size = math.floor(0.2 * nature_length)\n",
    "        self.nature_train, self.nature_val = random_split(self.nature_dataset,\n",
    "                                                          [train_size, val_size],\n",
    "                                                          generator=torch.Generator().manual_seed(self.seed))\n",
    "        return self\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(self.nature_train, batch_size=self.batch_size)\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        return DataLoader(self.nature_val, batch_size=self.batch_size)\n",
    "\n",
    "    def predict_dataloader(self):\n",
    "        pass\n",
    "\n",
    "    def teardown(self, stage: str):\n",
    "        pass"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Training"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Writing the Model Class and Validation Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "import onnx\n",
    "\n",
    "def set_parameter_requires_grad(model, feature_extracting):\n",
    "    if feature_extracting:\n",
    "        for param in model.parameters():\n",
    "            param.requires_grad = False\n",
    "\n",
    "def initialize_model(model_name, num_classes, feature_extract, use_pretrained=True):\n",
    "    # Initialize these variables which will be set in this if statement. Each of these\n",
    "    #   variables is model specific.\n",
    "    model_ft = None\n",
    "    input_size = 0\n",
    "\n",
    "    if model_name == \"squeezenet\":\n",
    "        \"\"\" Squeezenet\n",
    "        \"\"\"\n",
    "        model_ft = models.squeezenet1_0(pretrained=use_pretrained)\n",
    "        set_parameter_requires_grad(model_ft, feature_extract)\n",
    "        model_ft.classifier[1] = torch.nn.Conv2d(512, num_classes, kernel_size=(1, 1), stride=(1, 1))\n",
    "        model_ft.num_classes = num_classes\n",
    "        input_size = 224\n",
    "\n",
    "    else:\n",
    "        print(\"Invalid model name, exiting...\")\n",
    "        exit()\n",
    "\n",
    "    return model_ft, input_size\n",
    "\n",
    "class NaturePyTorchModule(torch.nn.Module):\n",
    "    def __init__(self,\n",
    "                 model_name,\n",
    "                 num_classes=10,\n",
    "                 feature_extract=True,\n",
    "                 lr=0.01):\n",
    "        '''method used to define our model parameters'''\n",
    "        super().__init__()\n",
    "\n",
    "        self.model_name = model_name\n",
    "        self.num_classes = num_classes\n",
    "        self.feature_extract = feature_extract\n",
    "        self.lr = lr\n",
    "        self.model, self.input_size = initialize_model(model_name=self.model_name,\n",
    "                                                       num_classes=self.num_classes,\n",
    "                                                       feature_extract=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        '''method used for inference input -> output'''\n",
    "        x = self.model(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "def evaluate_model(model, eval_data, idx_to_class, class_names, epoch_ndx):\n",
    "    device = torch.device(\"cpu\")\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    preds = []\n",
    "    actual = []\n",
    "\n",
    "    val_table = wandb.Table(columns=['pred', 'actual', 'image'])\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for data, target in eval_data:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            test_loss += F.nll_loss(\n",
    "                output, target, reduction=\"sum\"\n",
    "            ).item()  # sum up batch loss\n",
    "            pred = output.argmax(\n",
    "                dim=1, keepdim=True\n",
    "            )  # get the index of the max log-probability\n",
    "            preds += list(pred.flatten().tolist())\n",
    "            actual += target.numpy().tolist()\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "            for idx, img in enumerate(data):\n",
    "                img = img.numpy().transpose(1, 2, 0)\n",
    "                pred_class = idx_to_class[pred.numpy()[idx][0]]\n",
    "                target_class = idx_to_class[target.numpy()[idx]]\n",
    "                val_table.add_data(pred_class, target_class, wandb.Image(img))\n",
    "\n",
    "    test_loss /= len(eval_data.dataset)\n",
    "    accuracy = 100.0 * correct / len(eval_data.dataset)\n",
    "    conf_mat = wandb.plot.confusion_matrix(y_true=actual, preds=preds, class_names=class_names)\n",
    "    return test_loss, accuracy, preds, val_table, conf_mat"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logging Model Checkpoints as part of your Training Loop\n",
    "W&B Artifacts enables users to log and version large serialized files, such as model checkpoints.\n",
    "\n",
    "The `Artifact` class can encapsulate arbitrary files and directories.  The artifact has\n",
    "* a name\n",
    "* a type\n",
    "* metadata\n",
    "* description\n",
    "* files, directory of files, or references to external object stores (e.g. s3)\n",
    "\n",
    "Example usage:\n",
    "```\n",
    "run = wandb.init(project = \"my-project\")\n",
    "artifact = wandb.Artifact(name = \"my_artifact\", type = \"model\")\n",
    "artifact.add_file(\"/path/to/my/file.txt\")\n",
    "run.log_artifact(artifact)\n",
    "run.finish()\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%wandb -h 600\n",
    "\n",
    "run = wandb.init(project=PROJECT_NAME,\n",
    "                entity=ENTITY,\n",
    "                job_type='training',\n",
    "                config={'model_type': 'squeezenet',\n",
    "                        'lr': 1.0,\n",
    "                        'gamma': 0.75,\n",
    "                        'batch_size': 16,\n",
    "                        'epochs': 5})\n",
    "\n",
    "model = NaturePyTorchModule(wandb.config['model_type'])\n",
    "wandb.watch(model)\n",
    "\n",
    "wandb.config['input_size'] = 224\n",
    "\n",
    "nature_module = NatureDatasetModule(wandb_run = run,\n",
    "                                    artifact_name_alias=\"Nature_100:latest\",\n",
    "                                    local_target_dir=\"Nature_100:latest\",\n",
    "                                    batch_size=wandb.config['batch_size'],\n",
    "                                    input_size=wandb.config['input_size'])\n",
    "nature_module.setup()\n",
    "\n",
    "# Train the model\n",
    "learning_rate = wandb.config[\"lr\"]\n",
    "gamma = wandb.config[\"gamma\"]\n",
    "epochs = wandb.config[\"epochs\"]\n",
    "\n",
    "device = torch.device(\"cpu\")\n",
    "optimizer = optim.Adadelta(model.parameters(), lr=wandb.config['lr'])\n",
    "scheduler = StepLR(optimizer, step_size=1, gamma=wandb.config['gamma'])\n",
    "\n",
    "best_loss = float(\"inf\")\n",
    "best_model = None\n",
    "\n",
    "for epoch_ndx in range(epochs):\n",
    "  model.train()\n",
    "  for batch_ndx, batch in enumerate(nature_module.train_dataloader()):\n",
    "      data, target = batch[0].to(\"cpu\"), batch[1].to(\"cpu\")\n",
    "      optimizer.zero_grad()\n",
    "      preds = model(data)\n",
    "      loss = F.nll_loss(preds, target)\n",
    "      loss.backward()\n",
    "      optimizer.step()\n",
    "      scheduler.step()\n",
    "\n",
    "      ### Log your metrics ###\n",
    "      wandb.log({\n",
    "          \"train/epoch_ndx\": epoch_ndx,\n",
    "          \"train/batch_ndx\": batch_ndx,\n",
    "          \"train/train_loss\": loss,\n",
    "          \"train/learning_rate\": optimizer.param_groups[0][\"lr\"]\n",
    "      })\n",
    "\n",
    "  ### Evaluation at the end of each epoch ###\n",
    "  model.eval()\n",
    "  test_loss, accuracy, preds, val_table, conf_mat = evaluate_model(model,\n",
    "                                                                  nature_module.val_dataloader(),\n",
    "                                                                  nature_module.nature_dataset.idx_to_class,\n",
    "                                                                  nature_module.nature_dataset.class_names,\n",
    "                                                                  epoch_ndx)\n",
    "\n",
    "  is_best = test_loss < best_loss\n",
    "\n",
    "  wandb.log({'eval/test_loss': test_loss,\n",
    "              'eval/accuracy': accuracy,\n",
    "              'eval/conf_mat': conf_mat,\n",
    "              'eval/val_table': val_table})\n",
    "\n",
    "  ### Checkpoing your model weights ###\n",
    "  x = torch.randn(1, 3, 224, 224, requires_grad=True)\n",
    "  torch.onnx.export(model,              # model being run\n",
    "            x,                         # model input (or a tuple for multiple inputs)\n",
    "            \"model.onnx\",   # where to save the model (can be a file or file-like object)\n",
    "            export_params=True,        # store the trained parameter weights inside the model file\n",
    "            opset_version=10,          # the ONNX version to export the model to\n",
    "            do_constant_folding=True,  # whether to execute constant folding for optimization\n",
    "            input_names = ['input'],   # the model's input names\n",
    "            output_names = ['output'], # the model's output names\n",
    "            dynamic_axes={'input' : {0 : 'batch_size'},    # variable length axes\n",
    "                          'output' : {0 : 'batch_size'}})\n",
    "\n",
    "  art = wandb.Artifact(f\"anomaly-classifier-{wandb.run.id}\",\n",
    "                        type=\"model\",\n",
    "                        metadata={'format': 'onnx',\n",
    "                                'num_classes': len(nature_module.nature_dataset.class_names),\n",
    "                                'model_type': wandb.config['model_type'],\n",
    "                                'model_input_size': wandb.config['input_size'],\n",
    "                                'index_to_class': nature_module.nature_dataset.idx_to_class})\n",
    "\n",
    "  art.add_file(\"model.onnx\")\n",
    "\n",
    "  ### Add aliases to keep track of your best checkpoints over time\n",
    "  wandb.log_artifact(art, aliases=[\"best\", \"latest\"] if is_best else None)\n",
    "  if is_best:\n",
    "      best_model = art"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Manage all your model checkpoints for a project under one roof.\n",
    "\n",
    "![api_token](https://drive.google.com/uc?export=view&id=1z7nXRgqHTPYjfR1SoP-CkezyxklbAZlM)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating Registered Models and Linking through the **API**\n",
    "You can [link a model via api](https://docs.wandb.ai/guides/models) with `wandb.run.link_artifact` passing in the artifact object, and the name of the **Registered Model**, along with aliases you want to append to it. **Registered Models** are entity (team) scoped in W&B so only members of a team can see and access the **Registered Models** there. You indicate a registered model name via api with `<entity>/model-registry/<registered-model-name>`. If a Registered Model doesn't exist, one will be created automatically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.run.link_artifact(best_model, 'wandb/model-registry/Model Registry Tutorial', aliases=['staging'])\n",
    "wandb.finish()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Consuming a Registered Model\n",
    "You now can consume any registered model via API by referring the corresponding `name:alias`. Model consumers, whether they are engineers, researchers, or CI/CD processes, can go to the model registry as the central hub for all models that should \"see the light of day\": those that need to go through testing or move to production."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%wandb -h 600\n",
    "\n",
    "run = wandb.init(project=PROJECT_NAME, entity=ENTITY, job_type='inference')\n",
    "artifact = run.use_artifact('wandb/model-registry/Model Registry Tutorial:staging', type='model')\n",
    "artifact_dir = artifact.download()\n",
    "wandb.finish()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "include_colab_link": true,
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
