{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/wandb/edu/blob/main/model-registry-201/Consuming_Registered_Models.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>\n",
    "<!--- @wandbcode{modelreg201-consume} -->"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Consume a Registered Model\n",
    "- Names and aliases offer a simple handle to retrieve Registered Model versions\n",
    "- Facilitate easy hand-off between teams and processes\n",
    "<!--- @wandbcode{wandb201-consume} -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q bitsandbytes datasets accelerate loralib\n",
    "!pip install -q git+https://github.com/huggingface/transformers.git@main git+https://github.com/huggingface/peft.git\n",
    "!pip install -q wandb\n",
    "!pip install -q ctranslate2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb\n",
    "wandb.login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "project_name = \"model-registry-201\" #@param\n",
    "entity = \"wandb\" #@param"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from peft import PeftModel, PeftConfig\n",
    "from transformers import AutoTokenizer, AutoConfig, AutoModelForCausalLM\n",
    "import os\n",
    "\n",
    "def convert_qlora2ct2(adapter_path='model-registry/OPT-125M:latest',\n",
    "                      full_model_path=\"opt125m-finetuned\",\n",
    "                      offload_path=\"opt125m-offload\",\n",
    "                      ct2_path=\"opt125m-finetuned-ct2\",\n",
    "                      quantization=\"int8\"):\n",
    "\n",
    "\n",
    "    peft_model_id = adapter_path\n",
    "    peftconfig = PeftConfig.from_pretrained(peft_model_id)\n",
    "\n",
    "    model = AutoModelForCausalLM.from_pretrained(\n",
    "      \"facebook/opt-125m\",\n",
    "      offload_folder  = offload_path,\n",
    "      device_map='auto',\n",
    "    )\n",
    "\n",
    "    tokenizer = AutoTokenizer.from_pretrained(\"facebook/opt-125m\")\n",
    "\n",
    "    model = PeftModel.from_pretrained(model, peft_model_id)\n",
    "\n",
    "    print(\"Peft model loaded\")\n",
    "\n",
    "    merged_model = model.merge_and_unload()\n",
    "\n",
    "    merged_model.save_pretrained(full_model_path)\n",
    "    tokenizer.save_pretrained(full_model_path)\n",
    "\n",
    "    if quantization == False:\n",
    "        os.system(f\"ct2-transformers-converter --model {full_model_path} --output_dir {ct2_path} --force\")\n",
    "    else:\n",
    "        os.system(f\"ct2-transformers-converter --model {full_model_path} --output_dir {ct2_path} --quantization {quantization} --force\")\n",
    "    print(\"Convert successfully\")\n",
    "    return merged_model, tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ctranslate2\n",
    "import wandb\n",
    "\n",
    "\n",
    "wandb.init(project=project_name, entity=entity, job_type=\"ctranslate2\")\n",
    "\n",
    "best_model = wandb.use_artifact(f'{entity}/model-registry/Review Summarization:staging')\n",
    "best_model.download(root='model-registry/Review-Summarization:staging')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process the model\n",
    "- Quantize, convert formats, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quantizing the model to int8\n",
    "merged_model, tokenizer = convert_qlora2ct2(adapter_path='model-registry/Review-Summarization:staging',\n",
    "                                            ct2_path='model-registry/Review-Summarization-quantized')\n",
    "\n",
    "# Log the quantized model to the registry\n",
    "model_art = wandb.Artifact('review-summary-ct2-quantized', type=\"model\")\n",
    "model_art.add_dir('model-registry/Review-Summarization-quantized')\n",
    "wandb.run.link_artifact(model_art, f'{entity}/model-registry/Review Summarization', aliases=['quantized'])\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Inference on a Test Dataset\n",
    "- Log the results in a W&B Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run inference on a test set and log results to W&B\n",
    "generator = ctranslate2.Generator(\"model-registry/Review-Summarization-quantized\")\n",
    "\n",
    "reviews = [\n",
    "    \"BlastMaster 3000 Vacuum Cleaner: I never knew cleaning could be this easy until I got the BlastMaster 3000! It glides effortlessly across all surfaces and picks up even the tiniest of dust particles. The only downside is that it's a bit noisy, but the power it packs more than makes up for it.\",\n",
    "    \"Sunrise Organic Facial Cream: I've been using Sunrise Organic Facial Cream for a month now, and the results are astonishing. My skin feels softer, smoother, and looks radiant. However, I wish the fragrance was a bit milder; it's a tad overpowering for my liking.\",\n",
    "    \"MellowTunes Wireless Earbuds: The sound quality of the MellowTunes earbuds is surprisingly good for its price range. They fit comfortably in my ears and the battery life lasts an entire day of listening. Just wish they came with a case that was a bit more durable.\"\n",
    "]\n",
    "\n",
    "prompts = [f\"Summarize this review {review}\" for review in reviews]\n",
    "\n",
    "\n",
    "test_table = wandb.Table(columns=[\"review\", \"summary\"])\n",
    "\n",
    "for r, p in zip(reviews, prompts):\n",
    "  start_tokens = tokenizer.convert_ids_to_tokens(tokenizer.encode(p))\n",
    "  results = generator.generate_batch([start_tokens], max_length=100)\n",
    "  output = tokenizer.decode(results[0].sequences_ids[0])\n",
    "  test_table.add_data(r, p)\n",
    "\n",
    "wandb.log({\"test_table\": test_table})\n",
    "wandb.finish()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Query a Registered Model's upstream and downstream run data\n",
    "- Walk the pipeline DAG with the API to retrieve upstream training run data or downstream testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb\n",
    "\n",
    "api = wandb.Api()\n",
    "\n",
    "registered_model_quantized = api.artifact(f'{entity}/model-registry/Review Summarization:quantized')\n",
    "\n",
    "# Get info about the quantization run\n",
    "quantizing_run = registered_model_quantized.logged_by()\n",
    "print(quantizing_run.summary)\n",
    "\n",
    "registered_model_checkpoint = list(filter(lambda x: \"checkpoint\" in x.name,\n",
    "                                     quantizing_run.used_artifacts()))[0]\n",
    "\n",
    "training_run =registered_model_checkpoint.logged_by()\n",
    "print(training_run.history())"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "include_colab_link": true,
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
