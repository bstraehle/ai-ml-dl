{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9f40c232-df6e-49df-9016-6459e4af2e1e",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Coding Self-Attention in PyTroch!!!\n",
    "\n",
    "By Josh Starmer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc125fb6-069e-4fc1-b153-af417c535b2c",
   "metadata": {},
   "source": [
    "<p style=\"background-color:#fff6e4; padding:15px; border-width:3px; border-color:#f5ecda; border-style:solid; border-radius:6px\"> ‚è≥ <b>Note <code>(Kernel Starting)</code>:</b> This notebook takes about 30 seconds to be ready to use. You may start and watch the video while you wait.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4226d63-8d76-40bc-a8e6-0f290a159418",
   "metadata": {},
   "source": [
    "---- \n",
    "\n",
    "In this tutorial, we will code **Self-Attention** in **[PyTorch](https://pytorch.org/)**. **Attention** is an essential component of neural network **Transformers**, which are driving the current excitement in **Large Language Models** and **AI**. Specifically, an **Enecoder-Only Transformer**, illustrated below, is the foundation for the popular model **BERT**. \n",
    "\n",
    "<img src=\"./images/encoder_only_1.png\" alt=\"an enecoder-only transformer neural network\" style=\"width: 800px;\">\n",
    "\n",
    "At the heart of **BERT** is **Self-Attention**, which allows it to establish relationships among the words, characters and symbols, that are used for input and collectively called **Tokens**. For example, in the illustration below, where the word **it** could potentially refer to either **pizza** or **oven**, **Attention** could help a **Transformer** establish the correctly relationship between the word **it** and **pizza**.\n",
    "\n",
    "<img src=\"./images/attention_ex_1.png\" alt=\"an illustration of how attention works\" style=\"width: 800px;\"/>\n",
    "\n",
    "In this tutorial, you will...\n",
    "\n",
    "- **[Code a Basic Self-Attention Class!!!](#selfAttention)** The basic self-attention class allows the transformer to establish relationships among words and tokens.\n",
    "\n",
    "- **[Calculate Self-Attention Values!!!](#calculate)** We'll then use the class that we created, SelfAttention, to calculate self-attention values for some sample data.\n",
    " \n",
    "- **[Verify The Calculations!!!](#validate)** Lastly, we'll validate the calculations made by the SelfAttention class..\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "855d3a52-a43e-44cf-b8b6-b2ce88bea382",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63b86036-1369-441c-a14d-3ba7bdaa103b",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Import the modules that will do all the work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c520e0b-c6e4-43ce-93f5-c0f2b5e75438",
   "metadata": {
    "height": 81
   },
   "outputs": [],
   "source": [
    "import torch ## torch let's us create tensors and also provides helper functions\n",
    "import torch.nn as nn ## torch.nn gives us nn.module() and nn.Linear()\n",
    "import torch.nn.functional as F # This gives us the softmax()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56b01434-9796-4f5f-9d39-341505c912d6",
   "metadata": {},
   "source": [
    "<p style=\"background-color:#fff6ff; padding:15px; border-width:3px; border-color:#efe6ef; border-style:solid; border-radius:6px\"> üíª &nbsp; <b>Access <code>requirements.txt</code> file:</b> 1) click on the <em>\"File\"</em> option on the top menu of the notebook and then 2) click on <em>\"Open\"</em>. For more help, please see the <em>\"Appendix - Tips and Help\"</em> Lesson.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e58ebb2-1798-41c3-9ff8-1b4f50605964",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "125c4f0d-83b6-488f-8d91-66c54776bf2f",
   "metadata": {},
   "source": [
    "# Code Self-Attention\n",
    "<a id=\"selfAttention\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3392130-cd25-4000-97bb-9612764c83a8",
   "metadata": {
    "height": 880
   },
   "outputs": [],
   "source": [
    "class SelfAttention(nn.Module): \n",
    "                            \n",
    "    def __init__(self, d_model=2,  \n",
    "                 row_dim=0, \n",
    "                 col_dim=1):\n",
    "        ## d_model = the number of embedding values per token.\n",
    "        ##           Because we want to be able to do the math by hand, we've\n",
    "        ##           the default value for d_model=2.\n",
    "        ##           However, in \"Attention Is All You Need\" d_model=512\n",
    "        ##\n",
    "        ## row_dim, col_dim = the indices we should use to access rows or columns\n",
    "\n",
    "        \n",
    "        super().__init__()\n",
    "        \n",
    "        ## Initialize the Weights (W) that we'll use to create the\n",
    "        ## query (q), key (k) and value (v) for each token\n",
    "        ## NOTE: A lot of implementations include bias terms when\n",
    "        ##       creating the the queries, keys, and values, but\n",
    "        ##       the original manuscript that described Attention,\n",
    "        ##       \"Attention Is All You Need\" did not, so we won't either\n",
    "        self.W_q = nn.Linear(in_features=d_model, out_features=d_model, bias=False)\n",
    "        self.W_k = nn.Linear(in_features=d_model, out_features=d_model, bias=False)\n",
    "        self.W_v = nn.Linear(in_features=d_model, out_features=d_model, bias=False)\n",
    "        \n",
    "        self.row_dim = row_dim\n",
    "        self.col_dim = col_dim\n",
    "\n",
    "        \n",
    "    def forward(self, token_encodings):\n",
    "        ## Create the query, key and values using the encoding numbers\n",
    "        ## associated with each token (token encodings)\n",
    "        q = self.W_q(token_encodings)\n",
    "        k = self.W_k(token_encodings)\n",
    "        v = self.W_v(token_encodings)\n",
    "\n",
    "        ## Compute similarities scores: (q * k^T)\n",
    "        sims = torch.matmul(q, k.transpose(dim0=self.row_dim, dim1=self.col_dim))\n",
    "\n",
    "        ## Scale the similarities by dividing by sqrt(k.col_dim)\n",
    "        scaled_sims = sims / torch.tensor(k.size(self.col_dim)**0.5)\n",
    "\n",
    "        ## Apply softmax to determine what percent of each tokens' value to\n",
    "        ## use in the final attention values.\n",
    "        attention_percents = F.softmax(scaled_sims, dim=self.col_dim)\n",
    "\n",
    "        ## Scale the values by their associated percentages and add them up.\n",
    "        attention_scores = torch.matmul(attention_percents, v)\n",
    "\n",
    "        return attention_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c1a5352-4dfb-4968-bab7-8b638505203c",
   "metadata": {},
   "source": [
    "# BAM!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "371cd1e0-0216-438d-a241-05533e4b374d",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c75aaaa3-29e0-4c03-8a11-816bd4b7aea3",
   "metadata": {},
   "source": [
    "# Calculate Self-Attention\n",
    "<a id=\"calculate\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c17a35a-ceee-4502-9a25-9adbe6a0a1a8",
   "metadata": {
    "height": 285
   },
   "outputs": [],
   "source": [
    "## create a matrix of token encodings...\n",
    "encodings_matrix = torch.tensor([[1.16, 0.23],\n",
    "                                 [0.57, 1.36],\n",
    "                                 [4.41, -2.16]])\n",
    "\n",
    "## set the seed for the random number generator\n",
    "torch.manual_seed(42)\n",
    "\n",
    "## create a basic self-attention ojbect\n",
    "selfAttention = SelfAttention(d_model=2,\n",
    "                               row_dim=0,\n",
    "                               col_dim=1)\n",
    "\n",
    "## calculate basic attention for the token encodings\n",
    "selfAttention(encodings_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f59e708-88f6-4a71-98fa-c2593c0a79c7",
   "metadata": {},
   "source": [
    "# DOUBLE BAM!!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1153eec7-5573-41f7-b7de-3106b2ca07f9",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c25086ad-92d0-4396-8484-d9dab376ef50",
   "metadata": {},
   "source": [
    "# Print Out Weights and Verify Calculations\n",
    "<a id=\"validate\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ceddcba-be60-46fe-80bd-fa74e97ea62f",
   "metadata": {
    "height": 64
   },
   "outputs": [],
   "source": [
    "## print out the weight matrix that creates the queries\n",
    "selfAttention.W_q.weight.transpose(0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03331fba-9985-48e0-92ba-d72118c7a9c0",
   "metadata": {
    "height": 64
   },
   "outputs": [],
   "source": [
    "## print out the weight matrix that creates the keys\n",
    "selfAttention.W_k.weight.transpose(0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89d1e184-4fd0-4e6c-bd24-6916df2f76d8",
   "metadata": {
    "height": 64
   },
   "outputs": [],
   "source": [
    "## print out the weight matrix that creates the values\n",
    "selfAttention.W_v.weight.transpose(0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55d27388-5b15-4ee5-b39c-61903df18286",
   "metadata": {
    "height": 48
   },
   "outputs": [],
   "source": [
    "## calculate the queries\n",
    "selfAttention.W_q(encodings_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4b3425e-7b2f-4282-b4df-a2da6712c1c6",
   "metadata": {
    "height": 48
   },
   "outputs": [],
   "source": [
    "## calculate the keys\n",
    "selfAttention.W_k(encodings_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ff03c5b-62a6-4cda-94fc-1aac994e4ad5",
   "metadata": {
    "height": 48
   },
   "outputs": [],
   "source": [
    "## calculate the values\n",
    "selfAttention.W_v(encodings_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d88e411-84ac-4759-abcf-512cf8ff0670",
   "metadata": {
    "height": 48
   },
   "outputs": [],
   "source": [
    "q = selfAttention.W_q(encodings_matrix)\n",
    "q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95e191e2-fab3-4290-8085-b64b436dc5e7",
   "metadata": {
    "height": 48
   },
   "outputs": [],
   "source": [
    "k = selfAttention.W_k(encodings_matrix)\n",
    "k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4f55998-e89b-40b6-9021-f764ba32a3b5",
   "metadata": {
    "height": 64
   },
   "outputs": [],
   "source": [
    "sims = torch.matmul(q, k.transpose(dim0=0, dim1=1))\n",
    "sims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84693537-1874-4698-963a-75c9075b4bb7",
   "metadata": {
    "height": 48
   },
   "outputs": [],
   "source": [
    "scaled_sims = sims / (torch.tensor(2)**0.5)\n",
    "scaled_sims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bbc718e-c73c-4713-8b29-73962e39645d",
   "metadata": {
    "height": 64
   },
   "outputs": [],
   "source": [
    "attention_percents = F.softmax(scaled_sims, dim=1)\n",
    "attention_percents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c2edce0-9720-41ba-8916-e3415ef05e81",
   "metadata": {
    "height": 47
   },
   "outputs": [],
   "source": [
    "torch.matmul(attention_percents, selfAttention.W_v(encodings_matrix))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2154b417-e257-4eb8-bd19-7d54c3f3ecd5",
   "metadata": {},
   "source": [
    "# TRIPLE BAM!!!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
