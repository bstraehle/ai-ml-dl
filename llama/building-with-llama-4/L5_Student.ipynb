{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1021654a-a332-4104-be2b-6b1a32e2ddf1",
   "metadata": {},
   "source": [
    "# L5: Long-context understanding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9238c61d-9499-4d8e-bf74-9cf36b96f23b",
   "metadata": {},
   "source": [
    "<p style=\"background-color:#fff6e4; padding:15px; border-width:3px; border-color:#f5ecda; border-style:solid; border-radius:6px\"> ‚è≥ <b>Note <code>(Kernel Starting)</code>:</b> This notebook takes about 30 seconds to be ready to use. You may start and watch the video while you wait.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b335f98f-c0aa-49fc-bedc-9c1f0bf6d7a0",
   "metadata": {
    "height": 47
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ae630b5-a8ca-450c-a244-5d93cbb073a9",
   "metadata": {},
   "source": [
    "## Load API keys and libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cccd58bb-ec91-49c0-bc82-5f8246f92472",
   "metadata": {
    "height": 232
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from utils import get_llama_api_key, get_llama_base_url, get_together_api_key\n",
    "from utils import get_hf_access_token, get_github_access_token\n",
    "\n",
    "llama_api_key = get_llama_api_key()\n",
    "llama_base_url = get_llama_base_url()\n",
    "together_api_key = get_together_api_key()\n",
    "hf_access_token = get_hf_access_token()\n",
    "github_access_token = get_github_access_token()\n",
    "\n",
    "from utils import llama4, llama4_together\n",
    "from transformers import AutoTokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cda4d8fa-a041-4de2-b188-18bff717528b",
   "metadata": {},
   "source": [
    "<div style=\"background-color:#fff6ff; padding:13px; border-width:3px; border-color:#efe6ef; border-style:solid; border-radius:6px\">\n",
    "<p> üíª &nbsp; <b>Access <code>requirements.txt</code> and <code>helper.py</code> files:</b> 1) click on the <em>\"File\"</em> option on the top menu of the notebook and then 2) click on <em>\"Open\"</em>.</p>\n",
    "\n",
    "<p> ‚¨á &nbsp; <b>Download Notebooks:</b> 1) click on the <em>\"File\"</em> option on the top menu of the notebook and then 2) click on <em>\"Download as\"</em> and select <em>\"Notebook (.ipynb)\"</em>.</p>\n",
    "\n",
    "<p> üìí &nbsp; For more help, please see the <em>\"Appendix ‚Äì Tips, Help, and Download\"</em> Lesson.</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "229ccd49-5258-4646-8517-b1fad334acdf",
   "metadata": {
    "height": 62
   },
   "outputs": [],
   "source": [
    "model_id = \"meta-llama/Llama-4-Scout-17B-16E-Instruct\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8b86aa8-d3b6-4d12-b8d7-fc7866675a23",
   "metadata": {
    "height": 64
   },
   "outputs": [],
   "source": [
    "prompt = \"This is a test prompt.\"\n",
    "num_tokens = len(tokenizer.encode(prompt))\n",
    "print(f\"Number of tokens: {num_tokens}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7191466e-250f-404b-9c7c-9fb7b4cf6d48",
   "metadata": {},
   "source": [
    "## Large book"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46a6a1a8-53d9-4ba1-9367-e45d62fd711c",
   "metadata": {
    "height": 79
   },
   "outputs": [],
   "source": [
    "with open(\"files/war-and-peace.txt\", \"r\", encoding='utf=8') as file:\n",
    "    wp = file.read()\n",
    "len(wp), len(tokenizer.encode(wp))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8165bcb9-2300-444f-ab84-36a63db76651",
   "metadata": {},
   "source": [
    "<p style=\"background-color:#f7fff8; padding:15px; border-width:3px; border-color:#e0f0e0; border-style:solid; border-radius:6px\"> üö®\n",
    "&nbsp; <b>Different Run Results:</b> The output generated by AI chat models can vary with each execution due to their dynamic, probabilistic nature. Don't be surprised if your results differ from those shown in the video.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6ec5c2f-c274-4f93-b181-e2f8be467525",
   "metadata": {
    "height": 45
   },
   "outputs": [],
   "source": [
    "print(llama4_together(f\"give me a summary of the book below: {wp}\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24d6e4a5-cacf-405f-a35c-40d1a5f7dcbf",
   "metadata": {},
   "source": [
    "## Multiple document summarization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a28c9e9-1cd5-4b2b-9416-7aafb9297066",
   "metadata": {
    "height": 232
   },
   "outputs": [],
   "source": [
    "from utils import pdf2text\n",
    "\n",
    "papers = [\"2407.16833.pdf\", \"2409.01666.pdf\", \"2411.03538.pdf\", \"2503.17407.pdf\", \"2404.06654.pdf\"]\n",
    "paper_texts = []\n",
    "for n, paper in enumerate(papers):\n",
    "  text = pdf2text(f\"files/{paper}\")\n",
    "  paper_texts.append(f\"Paper {n+1}:\\n{text}\")\n",
    "  print(paper, len(text), len(tokenizer.encode(text)))\n",
    "\n",
    "total_text = \"\\n\\n\".join(paper_texts)\n",
    "print(f\"\"\"Total papers: {len(total_text)},\n",
    "{len(tokenizer.encode(total_text))}\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bb825fe-d586-4a92-9c92-2ec0c2690e50",
   "metadata": {
    "height": 62
   },
   "outputs": [],
   "source": [
    "print(llama4_together(f\"\"\"give me a summary of the five papers\n",
    "below: {total_text}\"\"\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe601f77-2902-46cb-b37b-1e61a06cca0d",
   "metadata": {},
   "source": [
    "## Single-hop codebase question answering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "378a2ff9-ea3e-481f-b215-ab342340d2ee",
   "metadata": {
    "height": 283
   },
   "outputs": [],
   "source": [
    "from utils import download_and_extract_repo, get_py_files, write_files_to_text\n",
    "\n",
    "repo_url = \"https://github.com/meta-llama/llama-models\"\n",
    "repo_name = repo_url.rstrip('/').split('/')[-1]\n",
    "extract_dir = f\"./{repo_name}\"\n",
    "\n",
    "download_repo = False # The repo is already downloaded and extracted on the platform. If you wouldf like to try this for another repo, please change this to True.\n",
    "if download_repo:\n",
    "    download_and_extract_repo(repo_url, extract_dir)\n",
    "\n",
    "py_files = get_py_files(extract_dir)\n",
    "output_file = f\"files/{repo_name}_files.txt\"\n",
    "write_files_to_text(py_files, output_file)\n",
    "\n",
    "print(f\"Output written to {output_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33250074-4e92-43bc-b436-5646da901086",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": [
    "!head -100 files/llama-models_files.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff7635eb-da7a-4ded-9bc7-3f9c64bbea2e",
   "metadata": {
    "height": 62
   },
   "outputs": [],
   "source": [
    "with open(\"files/llama-models_files.txt\", \"r\", encoding='utf=8') as file:\n",
    "    repo = file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9365464e-7d56-4ba3-bb0c-54c951a9c6e7",
   "metadata": {
    "height": 113,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "prompt = f\"\"\"Which file in the content below, which consists of a list\n",
    "of source file path and its content, has the function _encode_image\n",
    "defined? content:\n",
    "{repo}\"\"\"\n",
    "print(llama4_together(prompt))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c976d3b-f6db-493f-a705-646692ebccfe",
   "metadata": {},
   "source": [
    "## Analyze extensive user activity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efe1bf0d-4b34-4b18-adc6-0bf5ab01967b",
   "metadata": {
    "height": 351
   },
   "outputs": [],
   "source": [
    "from utils import get_pull_requests\n",
    "import pickle\n",
    "repo_owner = \"meta-llama\"\n",
    "repo_name = \"llama-cookbook\"\n",
    "\n",
    "# We have saved the pull_requests as a pickle file to make this run faster by loading files from local.\n",
    "cache_file = \"meta-llama_llama-cookbook_pull_requests.pkl\"\n",
    "load_cache_file = True\n",
    "\n",
    "if load_cache_file:\n",
    "    with open(cache_file, \"rb\") as f:\n",
    "        pull_requests = pickle.load(f)\n",
    "else:\n",
    "    pull_requests = get_pull_requests(repo_owner, repo_name)\n",
    "    with open(cache_file, \"wb\") as f:\n",
    "        pickle.dump(pull_requests, f)\n",
    "\n",
    "for pr in pull_requests:\n",
    "    print(pr[\"number\"], pr[\"title\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "326a0642-5239-421d-ac64-042a0e13666d",
   "metadata": {
    "height": 79
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "pickle.dump(pull_requests, open(f\"{repo_owner}_{repo_name}_pull_requests.pkl\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4db33e4a-ffa8-42f6-a078-0867a945c723",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": [
    "len(pull_requests)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56937fce-0f3c-4812-a7d8-9f8fd4aa9244",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": [
    "pull_requests[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ec81999-eb77-48aa-be91-72cc2a1f1813",
   "metadata": {
    "height": 215
   },
   "outputs": [],
   "source": [
    "from utils import get_pr_content\n",
    "\n",
    "all_content = []\n",
    "for pr in pull_requests:\n",
    "    pr_number = pr['number']\n",
    "    content = get_pr_content(repo_owner, repo_name,\n",
    "                             pr_number, github_access_token) # a github access token is needed to avoid the lower rate limit of making github requeests\n",
    "    if content:\n",
    "        all_content.append(f\"PR #{pr_number}: {content}\")\n",
    "\n",
    "len(all_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3266383-69ad-4240-a0a0-1be2c627c84c",
   "metadata": {
    "height": 62
   },
   "outputs": [],
   "source": [
    "all_pr_content = \"\\n\\n\".join(all_content)\n",
    "len(all_pr_content), len(tokenizer.encode(all_pr_content))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ac2452f-946e-435e-8929-5f82549c0b3a",
   "metadata": {
    "height": 98
   },
   "outputs": [],
   "source": [
    "query = \"how many PRs are about android or iOS?\"\n",
    "print(llama4_together(f\"\"\"{query}\n",
    "Below is all the PR info:\n",
    "{all_pr_content}\n",
    "\"\"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1f79641-d850-4814-a98f-e08fdc1731ac",
   "metadata": {
    "height": 147
   },
   "outputs": [],
   "source": [
    "query = f\"\"\"how many PRs are about agents? give a one-sentence\n",
    "summary of each, then a summary of all those agent PRs.\"\"\"\n",
    "\n",
    "print(llama4_together(f\"\"\"{query}\n",
    "Below is all the PR info:\n",
    "{all_pr_content}\n",
    "\"\"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e283ea3-77a0-4120-9b99-e63dfbf388fa",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "546162af-e8a7-4f37-9c30-4d8a071941e4",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12d8d953-cd71-4f4a-a115-6dbd5b318a43",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d7016b5-3835-40bd-b0a4-9484318abe25",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ee7318e-6585-4544-b4d4-b2bbd53e93ca",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62631094-ad78-41a2-a2d5-1998cd82f69b",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
