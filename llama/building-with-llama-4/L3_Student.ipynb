{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1021654a-a332-4104-be2b-6b1a32e2ddf1",
   "metadata": {},
   "source": [
    "# L3: Image Reasoning and Grounding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7393025-42f8-4bd4-ac29-21eac05f2d6c",
   "metadata": {},
   "source": [
    "<p style=\"background-color:#fff6e4; padding:15px; border-width:3px; border-color:#f5ecda; border-style:solid; border-radius:6px\"> ‚è≥ <b>Note <code>(Kernel Starting)</code>:</b> This notebook takes about 30 seconds to be ready to use. You may start and watch the video while you wait.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b05d478-5d58-4a60-b90d-214d208cba65",
   "metadata": {
    "height": 47
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d191e60-446d-4fe4-9f73-bf32dbf71b83",
   "metadata": {},
   "source": [
    "## Load API keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2876631c-db76-43d8-8f20-bc964d070cf1",
   "metadata": {
    "height": 130
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from utils import get_llama_api_key, get_llama_base_url, get_together_api_key\n",
    "\n",
    "llama_api_key = get_llama_api_key()\n",
    "llama_base_url = get_llama_base_url()\n",
    "together_api_key = get_together_api_key()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "132c0b7f-7a68-4cbe-8f22-04012235d297",
   "metadata": {},
   "source": [
    "<div style=\"background-color:#fff6ff; padding:13px; border-width:3px; border-color:#efe6ef; border-style:solid; border-radius:6px\">\n",
    "<p> üíª &nbsp; <b>Access <code>requirements.txt</code> and <code>helper.py</code> files:</b> 1) click on the <em>\"File\"</em> option on the top menu of the notebook and then 2) click on <em>\"Open\"</em>.</p>\n",
    "\n",
    "<p> ‚¨á &nbsp; <b>Download Notebooks:</b> 1) click on the <em>\"File\"</em> option on the top menu of the notebook and then 2) click on <em>\"Download as\"</em> and select <em>\"Notebook (.ipynb)\"</em>.</p>\n",
    "\n",
    "<p> üìí &nbsp; For more help, please see the <em>\"Appendix ‚Äì Tips, Help, and Download\"</em> Lesson.</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d46af6ca-8ad9-400a-bd95-1062675f2fef",
   "metadata": {},
   "source": [
    "## Llama helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6ec5c2f-c274-4f93-b181-e2f8be467525",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": [
    "from utils import llama4, llama4_together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15c55a8f-5082-4166-8b9c-6f65c4c6754b",
   "metadata": {
    "height": 164
   },
   "outputs": [],
   "source": [
    "import base64\n",
    "\n",
    "def encode_image_to_base64(image_path):\n",
    "    \"\"\"\n",
    "    Encode a local image file to base64 string\n",
    "    \"\"\"\n",
    "    with open(image_path, \"rb\") as image_file:\n",
    "        return base64.b64encode(image_file.read()).decode('utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf50e767-be2b-4329-a77f-d08bd2bb7230",
   "metadata": {},
   "source": [
    "## Image Grounding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b85284c-10b9-4593-bd0d-82aeb9fc06c6",
   "metadata": {
    "height": 47
   },
   "outputs": [],
   "source": [
    "from utils import display_local_image\n",
    "display_local_image(\"images/tools.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bb825fe-d586-4a92-9c92-2ec0c2690e50",
   "metadata": {
    "height": 62
   },
   "outputs": [],
   "source": [
    "prompt = \"\"\"Which tools in the image can be used for measuring length?\n",
    "Provide bounding boxes for every recognized item.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "378a2ff9-ea3e-481f-b215-ab342340d2ee",
   "metadata": {
    "height": 79
   },
   "outputs": [],
   "source": [
    "base64_tools = encode_image_to_base64(\"images/tools.png\")\n",
    "\n",
    "print(llama4(prompt,[f\"data:image/jpeg;base64,{base64_tools}\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98397945-4c85-48df-b464-b954464d2486",
   "metadata": {
    "height": 96
   },
   "outputs": [],
   "source": [
    "from utils import parse_output, draw_bounding_boxes\n",
    "output = llama4(prompt, [f\"data:image/jpeg;base64,{base64_tools}\"])\n",
    "tools = parse_output(output)\n",
    "draw_bounding_boxes(\"images/tools.png\", tools)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b26a6dd7-fc86-44f1-b2cf-9426d080ddee",
   "metadata": {},
   "source": [
    "## Analyze table in PDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f49a6d5-51fe-4a21-8b3d-f4f5f1b8870f",
   "metadata": {
    "height": 198
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from pypdf import PdfReader\n",
    "\n",
    "def pdf2text(file : str):\n",
    "  text = ''\n",
    "  with Path(file).open(\"rb\") as f:\n",
    "    reader = PdfReader(f)\n",
    "    text = \"\\n\\n\".join([page.extract_text() for page in reader.pages])\n",
    "\n",
    "  return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff7635eb-da7a-4ded-9bc7-3f9c64bbea2e",
   "metadata": {
    "height": 45
   },
   "outputs": [],
   "source": [
    "meta_q4_2024_txt = pdf2text(\"Meta-Reports-Fourth-Quarter-and-Full-Year-2024-Results-2025.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9365464e-7d56-4ba3-bb0c-54c951a9c6e7",
   "metadata": {
    "height": 62
   },
   "outputs": [],
   "source": [
    "start = meta_q4_2024_txt.find(\"Fourth Quarter and Full Year 2024 Financial Highlights\")\n",
    "print(meta_q4_2024_txt[start:start+1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f2b2a97-24c1-401e-a362-7cfbbb83697d",
   "metadata": {
    "height": 113
   },
   "outputs": [],
   "source": [
    "prompt = f\"\"\"How much is 2024 operating margin based on Meta's financial\n",
    "quarter report below:\n",
    "{meta_q4_2024_txt}\n",
    "\"\"\"\n",
    "print(llama4(prompt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4db33e4a-ffa8-42f6-a078-0867a945c723",
   "metadata": {
    "height": 45
   },
   "outputs": [],
   "source": [
    "display_local_image(\"images/meta-q4-2024-highlights.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56937fce-0f3c-4812-a7d8-9f8fd4aa9244",
   "metadata": {
    "height": 96
   },
   "outputs": [],
   "source": [
    "base64_meta = encode_image_to_base64(\"images/meta-q4-2024-highlights.png\")\n",
    "prompt = \"\"\"How much is 2024 operating margin based on Meta's financial\n",
    "report?\"\"\"\n",
    "print(llama4(prompt, [f\"data:image/jpeg;base64,{base64_meta}\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bcfd72d-42d6-4763-bae7-6b5780d28da7",
   "metadata": {},
   "source": [
    "## Generating code from a screenshot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "300eea7a-5c22-4698-8a45-070dfa5efbe8",
   "metadata": {
    "height": 62
   },
   "outputs": [],
   "source": [
    "vid_frame_address = \"images/video_frame_1440.jpg\"\n",
    "display_local_image(vid_frame_address)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ec81999-eb77-48aa-be91-72cc2a1f1813",
   "metadata": {
    "height": 113
   },
   "outputs": [],
   "source": [
    "base64_image = encode_image_to_base64(vid_frame_address)\n",
    "prompt = \"\"\"If I want to change the temperature on the image,\n",
    "where should I click? Return the bounding box for the location.\"\"\"\n",
    "output = llama4(prompt, [f\"data:image/jpeg;base64,{base64_image}\"])\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b48b92e-5796-4cdb-9010-f2d92296334c",
   "metadata": {
    "height": 130
   },
   "outputs": [],
   "source": [
    "prompt = \"\"\"\"Write a python script that uses Gradio to implement\n",
    "the chatbot UI in the image.\"\"\"\n",
    "\n",
    "output = llama4(prompt,[f\"data:image/jpeg;base64,{base64_image}\"],\n",
    "                model=\"Llama-4-Maverick-17B-128E-Instruct-FP8\")\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33e1e09b-5349-44e7-83f8-bddbfac0aea7",
   "metadata": {
    "height": 623
   },
   "outputs": [],
   "source": [
    "import gradio as gr\n",
    "\n",
    "def chatbot_settings(temp, max_tokens, repetition, top_p, streaming):\n",
    "    return f\"Temperature: {temp}, Max Tokens: {max_tokens}, Repetition: {repetition}, Top P: {top_p}, Streaming: {streaming}\"\n",
    "\n",
    "def main():\n",
    "    with gr.Blocks() as demo:\n",
    "        with gr.Row():\n",
    "            with gr.Column(scale=3):\n",
    "                chatbot = gr.Chatbot(label=\"Llama-4-Maverick-17B-128E-Instruct-FP8\")\n",
    "                msg = gr.Textbox(label=\"Enter message...\")\n",
    "            with gr.Column(scale=1):\n",
    "                with gr.Group(\"Model settings\"):\n",
    "                    temp = gr.Slider(label=\"Temperature\", minimum=0, maximum=1, value=0.6)\n",
    "                    max_tokens = gr.Slider(label=\"Max tokens\", minimum=0, maximum=4096, value=2048)\n",
    "                    repetition = gr.Slider(label=\"Repetition\", minimum=0, maximum=2, value=1.0)\n",
    "                    top_p = gr.Slider(label=\"Top P\", minimum=0, maximum=1, value=0.9)\n",
    "                    streaming = gr.Checkbox(label=\"Streaming\", value=True)\n",
    "                    advanced = gr.Button(\"Advanced\")\n",
    "                    json_schema = gr.Button(\"JSON schema\")\n",
    "                    tools = gr.Button(\"Tools\")\n",
    "\n",
    "        def respond(message, history, temp, max_tokens, repetition, top_p, streaming):\n",
    "            # Here you would implement your chatbot's response logic\n",
    "            # For now, it just echoes the input\n",
    "            bot_message = f\"Echo: {message}\"\n",
    "            history.append((message, bot_message))\n",
    "            return \"\", history\n",
    "\n",
    "        msg.submit(respond, [msg, chatbot, temp, max_tokens, repetition, top_p, streaming], [msg, chatbot])\n",
    "\n",
    "    demo.launch()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba345c15-0047-4456-baf1-078a06a876a9",
   "metadata": {},
   "source": [
    "## Solving Math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3266383-69ad-4240-a0a0-1be2c627c84c",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": [
    "display_local_image(\"images/simple_math.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ac2452f-946e-435e-8929-5f82549c0b3a",
   "metadata": {
    "height": 79
   },
   "outputs": [],
   "source": [
    "base64_math = encode_image_to_base64(\"images/simple_math.png\")\n",
    "prompt = \"Answer the question in the image.\"\n",
    "print(llama4(prompt, [f\"data:image/png;base64,{base64_math}\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c41fa148-971b-4989-83c1-b5568e543a66",
   "metadata": {},
   "source": [
    "## Analyzing computer screen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "546162af-e8a7-4f37-9c30-4d8a071941e4",
   "metadata": {
    "height": 45
   },
   "outputs": [],
   "source": [
    "display_local_image(\"images/browser_screenshot.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12d8d953-cd71-4f4a-a115-6dbd5b318a43",
   "metadata": {
    "height": 96
   },
   "outputs": [],
   "source": [
    "base64_img = encode_image_to_base64(\"images/browser_screenshot.png\")\n",
    "prompt = \"\"\"Describe the screenshot in detail,\n",
    "including browser URL and tabs.\"\"\"\n",
    "print(llama4(prompt,[f\"data:image/png;base64,{base64_img}\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35252a41-2047-49c9-9c6a-bbdd9014da08",
   "metadata": {
    "height": 79
   },
   "outputs": [],
   "source": [
    "display_local_image(\"images/browser_screenshot.png\")\n",
    "prompt = \"\"\"If I want to go to the next lesson, what should I do?\"\"\"\n",
    "print(llama4(prompt,[f\"data:image/png;base64,{base64_img}\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5297b14-aa9c-4ecc-b94d-1f934743afc3",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e5f9c03-75ca-4ca8-b960-9ccd428ea201",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8e620dd-08b3-4f09-aab1-af8410ac67cb",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "471dcc0c-8e30-4088-a4dd-7442dc0fd3e3",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e9cf9be-91ef-438e-90ab-2420625fbdf1",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7ca23aa-fd72-404c-bb0d-d044e430ac62",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
