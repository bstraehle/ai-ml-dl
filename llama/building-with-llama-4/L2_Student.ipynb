{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1021654a-a332-4104-be2b-6b1a32e2ddf1",
   "metadata": {},
   "source": [
    "# L2: Llama API Quickstart"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62d9c703-0af8-486c-ac4c-032bdd08b74e",
   "metadata": {},
   "source": [
    "<p style=\"background-color:#fff6e4; padding:15px; border-width:3px; border-color:#f5ecda; border-style:solid; border-radius:6px\"> ‚è≥ <b>Note <code>(Kernel Starting)</code>:</b> This notebook takes about 30 seconds to be ready to use. You may start and watch the video while you wait.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0408352-7ff7-40b7-995b-ea5dab5d3f2d",
   "metadata": {
    "height": 47
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "847c9909-e1d4-4d57-9c01-e9fc2437d8fe",
   "metadata": {},
   "source": [
    "## Load API keys and libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8b86aa8-d3b6-4d12-b8d7-fc7866675a23",
   "metadata": {
    "height": 147
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from utils import get_llama_api_key, get_llama_base_url\n",
    "\n",
    "llama_api_key = get_llama_api_key()\n",
    "llama_base_url = get_llama_base_url()\n",
    "\n",
    "from llama_api_client import LlamaAPIClient"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e863e43-c903-49a7-8f1a-c3cd4796334d",
   "metadata": {},
   "source": [
    "<div style=\"background-color:#fff6ff; padding:13px; border-width:3px; border-color:#efe6ef; border-style:solid; border-radius:6px\">\n",
    "<p> üíª &nbsp; <b>Access <code>requirements.txt</code> and <code>helper.py</code> files:</b> 1) click on the <em>\"File\"</em> option on the top menu of the notebook and then 2) click on <em>\"Open\"</em>.</p>\n",
    "\n",
    "<p> ‚¨á &nbsp; <b>Download Notebooks:</b> 1) click on the <em>\"File\"</em> option on the top menu of the notebook and then 2) click on <em>\"Download as\"</em> and select <em>\"Notebook (.ipynb)\"</em>.</p>\n",
    "\n",
    "<p> üìí &nbsp; For more help, please see the <em>\"Appendix ‚Äì Tips, Help, and Download\"</em> Lesson.</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b4ab30f-324c-4eb2-a706-f7697909b724",
   "metadata": {},
   "source": [
    "## Llama API client Python library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46a6a1a8-53d9-4ba1-9367-e45d62fd711c",
   "metadata": {
    "height": 402
   },
   "outputs": [],
   "source": [
    "def llama4(prompt, image_urls=[],\n",
    "    model=\"Llama-4-Scout-17B-16E-Instruct-FP8\"  # or Llama-4-Maverick-17B-128E-Instruct-FP8\n",
    "):\n",
    "  image_urls_content = []\n",
    "  for url in image_urls:\n",
    "    image_urls_content.append(\n",
    "        {\"type\": \"image_url\", \"image_url\": {\"url\": url}})\n",
    "\n",
    "  content = [{\"type\": \"text\", \"text\": prompt}]\n",
    "  content.extend(image_urls_content)\n",
    "\n",
    "  client = LlamaAPIClient(api_key=llama_api_key)\n",
    "\n",
    "  response = client.chat.completions.create(\n",
    "    model=model,\n",
    "    messages=[{\n",
    "        \"role\": \"user\",\n",
    "        \"content\": content\n",
    "    }],\n",
    "    temperature=0\n",
    "  )\n",
    "  return response.completion_message.content.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6ec5c2f-c274-4f93-b181-e2f8be467525",
   "metadata": {
    "height": 45
   },
   "outputs": [],
   "source": [
    "print(llama4(\"A brief history of AI in 3 short sentences.\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa368a20-68df-4084-98dc-a111de1671eb",
   "metadata": {},
   "source": [
    "## Using OpenAI-compatible library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a28c9e9-1cd5-4b2b-9416-7aafb9297066",
   "metadata": {
    "height": 538
   },
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "def llama4(prompt,\n",
    "    image_urls=[],\n",
    "    model=\"Llama-4-Scout-17B-16E-Instruct-FP8\",  # or Llama-4-Maverick-17B-128E-Instruct-FP8\n",
    "    debug=False\n",
    "):\n",
    "  image_urls_content = []\n",
    "  for url in image_urls:\n",
    "    image_urls_content.append(\n",
    "        {\"type\": \"image_url\", \"image_url\": {\"url\": url}}) # TODO: for local image use {\"url\": \"data:image/png;base64,...\"}}\n",
    "\n",
    "  content = [{\"type\": \"text\", \"text\": prompt}]\n",
    "  content.extend(image_urls_content)\n",
    "\n",
    "  client = OpenAI(api_key=llama_api_key, base_url=llama_base_url)\n",
    "\n",
    "  response = client.chat.completions.create(\n",
    "    model=model,\n",
    "    messages=[{\n",
    "        \"role\": \"user\",\n",
    "        \"content\": content\n",
    "    }],\n",
    "    temperature=0\n",
    "  )\n",
    "\n",
    "  if debug:\n",
    "    print(response)\n",
    "\n",
    "  return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "378a2ff9-ea3e-481f-b215-ab342340d2ee",
   "metadata": {
    "height": 45
   },
   "outputs": [],
   "source": [
    "print(llama4(\"A brief history of AI in 3 short sentences.\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cc189ce-0cc3-4149-bcf8-1a8c6da16f58",
   "metadata": {},
   "source": [
    "## Asking question about a single image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33250074-4e92-43bc-b436-5646da901086",
   "metadata": {
    "height": 200
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def display_image(image_url):\n",
    "    response = requests.get(image_url)\n",
    "    img = Image.open(BytesIO(response.content))\n",
    "    plt.imshow(img)\n",
    "    plt.axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f49a6d5-51fe-4a21-8b3d-f4f5f1b8870f",
   "metadata": {
    "height": 62
   },
   "outputs": [],
   "source": [
    "img_url = \"https://raw.githubusercontent.com/meta-llama/llama-models/refs/heads/main/Llama_Repo.jpeg\"\n",
    "display_image(img_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff7635eb-da7a-4ded-9bc7-3f9c64bbea2e",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": [
    "print(llama4(\"What's in the image?\", [img_url]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25102b02-cda4-4b2f-a014-fa7df9fd58ff",
   "metadata": {},
   "source": [
    "## Asking question about multiple images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f2b2a97-24c1-401e-a362-7cfbbb83697d",
   "metadata": {
    "height": 79
   },
   "outputs": [],
   "source": [
    "img_url2 = \"https://raw.githubusercontent.com/meta-llama/PurpleLlama/refs/heads/main/logo.png\"\n",
    "display_image(img_url)\n",
    "display_image(img_url2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efe1bf0d-4b34-4b18-adc6-0bf5ab01967b",
   "metadata": {
    "height": 45
   },
   "outputs": [],
   "source": [
    "print(llama4(\"Compare these two images.\", [img_url, img_url2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be0cd299-00e3-442f-ab21-2d6357b926d5",
   "metadata": {},
   "source": [
    "## Llama 4 Long Context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56937fce-0f3c-4812-a7d8-9f8fd4aa9244",
   "metadata": {
    "height": 62
   },
   "outputs": [],
   "source": [
    "with open(\"A-tale-of-two-cities.txt\", \"r\", encoding='utf=8') as file:\n",
    "    tale = file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1124b18c-8599-4bec-9a9d-59f2dd26368d",
   "metadata": {
    "height": 96
   },
   "outputs": [],
   "source": [
    "question = \"\"\"What's the last utterance Sydney Carton would have given\n",
    "at the end of the book A Tale of Two Cities? Just give one.\n",
    "What's the paragraph before the last utterance?\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "300eea7a-5c22-4698-8a45-070dfa5efbe8",
   "metadata": {
    "height": 62
   },
   "outputs": [],
   "source": [
    "print(llama4(f\"{question} The book content is below: {tale[300000:]}\",\n",
    "      model=\"Llama-4-Maverick-17B-128E-Instruct-FP8\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95918f24-322f-4172-95ea-6742dd03a7c0",
   "metadata": {},
   "source": [
    "## Llama 4 Multilingual Support"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15b43ffb-6399-4031-aa28-fc46d936484f",
   "metadata": {
    "height": 96
   },
   "outputs": [],
   "source": [
    "question = \"\"\"how many languages do you understand?\n",
    "answer in all the languages you can speak.\"\"\"\n",
    "\n",
    "print(llama4(question))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33e1e09b-5349-44e7-83f8-bddbfac0aea7",
   "metadata": {
    "height": 521
   },
   "outputs": [],
   "source": [
    "client = OpenAI(api_key=llama_api_key, base_url=llama_base_url)\n",
    "\n",
    "class Polyglot:\n",
    "    def __init__(self, source=\"English\", target=\"French\", model=\"Llama-4-Scout-17B-16E-Instruct-FP8\"):\n",
    "        system = f\"\"\"You're a bilingual translator between two people:\n",
    "          the first person only speaks {source} and\n",
    "          the second person only speaks {target}.\n",
    "          For any user input, return as follows:\n",
    "          1. Recognized language: <the languege of the input,\n",
    "          either {source} or {target}>\n",
    "          2. Translation of the input: <the translation of the input to\n",
    "          the other language\n",
    "          3. Answer to the input: <in the same language as the\n",
    "          recognized language of the input>\"\"\"\n",
    "        self.messages = [{\"role\": \"system\", \"content\": system}]\n",
    "        self.model = model\n",
    "\n",
    "    def __call__(self, message):\n",
    "        self.messages.append({\"role\": \"user\", \"content\": message})\n",
    "        result = self.execute()\n",
    "        self.messages.append({\"role\": \"assistant\", \"content\": result})\n",
    "        return result\n",
    "\n",
    "    def execute(self):\n",
    "        response = client.chat.completions.create(\n",
    "                        model=self.model,\n",
    "                        temperature=0,\n",
    "                        messages=self.messages)\n",
    "        return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1697ea2-f145-443d-889a-ee82355f86b0",
   "metadata": {
    "height": 45
   },
   "outputs": [],
   "source": [
    "agent = Polyglot(source=\"English\", target=\"French\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ac2452f-946e-435e-8929-5f82549c0b3a",
   "metadata": {
    "height": 47
   },
   "outputs": [],
   "source": [
    "result = agent(\"Hello!\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1f79641-d850-4814-a98f-e08fdc1731ac",
   "metadata": {
    "height": 45
   },
   "outputs": [],
   "source": [
    "print(agent(\"How do you say the weather is nice in French?\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "546162af-e8a7-4f37-9c30-4d8a071941e4",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12d8d953-cd71-4f4a-a115-6dbd5b318a43",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0dc8e7f-2e30-4cb5-bc17-384020905ce2",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35252a41-2047-49c9-9c6a-bbdd9014da08",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5297b14-aa9c-4ecc-b94d-1f934743afc3",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "137e950c-2323-44df-ba78-af31eafa7b19",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
