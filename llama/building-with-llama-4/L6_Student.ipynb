{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c190e92f-9245-4333-a532-1fae97f41c27",
   "metadata": {},
   "source": [
    "# Prompt Optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5350abad-e099-4e7b-8d4d-e37fc9285fc6",
   "metadata": {},
   "source": [
    "## Load API Keys"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac06c78c-3a80-4ee3-8198-4a633045e699",
   "metadata": {},
   "source": [
    "<p style=\"background-color:#fff6e4; padding:15px; border-width:3px; border-color:#f5ecda; border-style:solid; border-radius:6px\"> ‚è≥ <b>Note <code>(Kernel Starting)</code>:</b> This notebook takes about 30 seconds to be ready to use. You may start and watch the video while you wait.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31fe38d6-537f-416a-a3ad-08fbdd541488",
   "metadata": {
    "height": 47
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2876631c-db76-43d8-8f20-bc964d070cf1",
   "metadata": {
    "height": 130
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from utils import get_llama_api_key, get_llama_base_url, get_together_api_key\n",
    "\n",
    "llama_api_key = get_llama_api_key()\n",
    "llama_base_url = get_llama_base_url()\n",
    "together_api_key = get_together_api_key()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46a6a1a8-53d9-4ba1-9367-e45d62fd711c",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": [
    "#!pip install llama-prompt-ops==0.0.7"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c5e4fb0-a0a9-43cb-b636-e8c9654f7075",
   "metadata": {},
   "source": [
    "<div style=\"background-color:#fff6ff; padding:13px; border-width:3px; border-color:#efe6ef; border-style:solid; border-radius:6px\">\n",
    "<p> üíª &nbsp; <b>Access <code>requirements.txt</code> and <code>helper.py</code> files:</b> 1) click on the <em>\"File\"</em> option on the top menu of the notebook and then 2) click on <em>\"Open\"</em>.</p>\n",
    "\n",
    "<p> ‚¨á &nbsp; <b>Download Notebooks:</b> 1) click on the <em>\"File\"</em> option on the top menu of the notebook and then 2) click on <em>\"Download as\"</em> and select <em>\"Notebook (.ipynb)\"</em>.</p>\n",
    "\n",
    "<p> üìí &nbsp; For more help, please see the <em>\"Appendix ‚Äì Tips, Help, and Download\"</em> Lesson.</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77db02ff-234d-4f19-b656-641fd125ff94",
   "metadata": {},
   "source": [
    "## Creating a sample project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15c55a8f-5082-4166-8b9c-6f65c4c6754b",
   "metadata": {
    "height": 62
   },
   "outputs": [],
   "source": [
    "## Check if the folder exists: In the line [ -d \"my-project\" ] returns true if the directory is present; the || (‚Äúor‚Äù) means llama-prompt-ops create my-project executes only when that first test is false\n",
    "![ -d \"my-project\" ] || llama-prompt-ops create my-project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b85284c-10b9-4593-bd0d-82aeb9fc06c6",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": [
    "!ls ./my-project/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7c78821-19c1-463d-9305-5fc97bee763c",
   "metadata": {},
   "source": [
    "## System prompt and dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c53d0950-b3c7-4713-99bc-47a8d1a1fc04",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": [
    "!cat my-project/prompts/prompt.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08521291-31dc-4f85-8aa1-86b8b965a82c",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": [
    "!head -15 my-project/data/dataset.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "378a2ff9-ea3e-481f-b215-ab342340d2ee",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": [
    "!cat my-project/config.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98397945-4c85-48df-b464-b954464d2486",
   "metadata": {
    "height": 436
   },
   "outputs": [],
   "source": [
    "%%writefile my-project/config.yaml\n",
    "system_prompt:\n",
    "  file: prompts/prompt.txt\n",
    "  inputs:\n",
    "  - question\n",
    "  outputs:\n",
    "  - answer\n",
    "dataset:\n",
    "  path: data/dataset.json\n",
    "  input_field:\n",
    "  - fields\n",
    "  - input\n",
    "  golden_output_field: answer\n",
    "model:\n",
    "  task_model: together_ai/meta-llama/Llama-4-Scout-17B-16E-Instruct\n",
    "  proposer_model: together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo\n",
    "  api_base: https://api.together.xyz/v1\n",
    "metric:\n",
    "  class: llama_prompt_ops.core.metrics.FacilityMetric\n",
    "  strict_json: false\n",
    "  output_field: answer\n",
    "optimization:\n",
    "  strategy: llama\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "415d3a27-d4e8-4f44-be33-c2a1f77b1ce9",
   "metadata": {},
   "source": [
    "## Running prompt optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12fcde8a-9d4f-4b11-be4a-91c3933cf014",
   "metadata": {},
   "source": [
    "<div style=\"background-color:#fff6ff; padding:13px; border-width:3px; border-color:#efe6ef; border-style:solid; border-radius:6px\">\n",
    "<p>Running prompt optimization can take a long time. To speed up running the notebooks, we will load saved results. You can change <code>run_optimization</code> to <code>True</code> to run the optimization.</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f49a6d5-51fe-4a21-8b3d-f4f5f1b8870f",
   "metadata": {
    "height": 96,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "run_optimization = False     # or chnage to True to run\n",
    "\n",
    "if run_optimization:\n",
    "    !cd my-project && llama-prompt-ops migrate --api-key-env TOGETHERAI_API_KEY"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "553cb2f6-0966-4ce9-b2b0-60b96503f1a8",
   "metadata": {},
   "source": [
    "## Analyzing the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f2b2a97-24c1-401e-a362-7cfbbb83697d",
   "metadata": {
    "height": 147
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "json_files = glob.glob(\"my-project/results/*.json\")\n",
    "\n",
    "import json\n",
    "with open(json_files[0], \"r\") as f:\n",
    "    data = json.load(f)\n",
    "optimized_prompt = data['prompt']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efe1bf0d-4b34-4b18-adc6-0bf5ab01967b",
   "metadata": {
    "height": 62
   },
   "outputs": [],
   "source": [
    "with open(\"my-project/prompts/prompt.txt\", \"r\", encoding=\"utf-8\") as file:\n",
    "    original_prompt = file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56937fce-0f3c-4812-a7d8-9f8fd4aa9244",
   "metadata": {
    "height": 181
   },
   "outputs": [],
   "source": [
    "from IPython.display import display, HTML\n",
    "\n",
    "def compare_strings_side_by_side(text1, text2):\n",
    "    html = '<table style=\"width: 100%; border-collapse: collapse;\"><tr><th>Original Prompt</th><th>Optimized Prompt</th></tr>'\n",
    "    html += f'<tr><td style=\"width:50% padding: 10px; vertical-align: top;\"><pre style=\"white-space: pre-wrap; word-wrap: break-word;\">{text1}</pre></td><td style=\"width: 50% padding: 10px; vertical-align: top;\"><pre style=\"white-space: pre-wrap; word-wrap: break-word;\">{text2}</pre></td></tr></table>'\n",
    "\n",
    "    display(HTML(html))\n",
    "\n",
    "compare_strings_side_by_side(original_prompt, optimized_prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be468a56-effe-4ed4-960e-1020315c914f",
   "metadata": {},
   "source": [
    "## Few-shot examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5297b14-aa9c-4ecc-b94d-1f934743afc3",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": [
    "data['few_shots'][0]['question']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c9476d0-35f5-488d-897f-0e3bbcde2524",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": [
    "data['few_shots'][0]['answer']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3359dc9e-9bf2-4272-88ae-41a8a7a46702",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": [
    "len(data['few_shots'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab19cc5b-2fdc-4b05-a6b2-71f6af2ca0cf",
   "metadata": {
    "height": 96
   },
   "outputs": [],
   "source": [
    "few_shots = \"\\n\\nFew shot examples\\n\\n\"\n",
    "for i, shot in enumerate(data['few_shots']):\n",
    "  few_shots += f\"\"\"Example {i+1}\\n=================\\nQuestion:\\n\n",
    "  {shot['question']}\\n\\nAnswer:\\n{shot['answer']}\\n\\n\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "555c36ff-3060-4857-8f6e-e98e9b007619",
   "metadata": {},
   "source": [
    "## Compare optimized and original prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f584214-3e31-4b9e-b666-d7a8d6908515",
   "metadata": {
    "height": 96
   },
   "outputs": [],
   "source": [
    "with open(\"my-project/data/dataset.json\", 'r') as f:\n",
    "  ds = json.load(f)\n",
    "\n",
    "len(ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bbdaa7b-40ae-43ea-94fb-7f8ea99f3f59",
   "metadata": {
    "height": 47
   },
   "outputs": [],
   "source": [
    "ds_test = ds[int(len(ds)*0.7):]\n",
    "len(ds_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb396e81-9458-4330-823e-7598e5f7c6f5",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": [
    "from utils import evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30979087-60fd-4871-a9dc-11774227a7a3",
   "metadata": {
    "height": 368
   },
   "outputs": [],
   "source": [
    "from together import Together\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "result_original = []\n",
    "client = Together()\n",
    "\n",
    "for entry in tqdm(ds_test):\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": original_prompt},\n",
    "        {\"role\": \"user\", \"content\": entry[\"fields\"][\"input\"]},\n",
    "    ]\n",
    "\n",
    "    response = client.chat.completions.create(\n",
    "      model=\"meta-llama/Llama-3.3-70B-Instruct-Turbo\",\n",
    "      messages=messages,\n",
    "      temperature=0\n",
    "    )\n",
    "\n",
    "    prediction = response.choices[0].message.content\n",
    "    result_original.append(evaluate(entry[\"answer\"], prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb88844f-1a18-4be1-9da5-2a9fdb2b9625",
   "metadata": {
    "height": 300
   },
   "outputs": [],
   "source": [
    "result_optimized = []\n",
    "\n",
    "for entry in tqdm(ds_test):\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": optimized_prompt + few_shots},\n",
    "        {\"role\": \"user\", \"content\": entry[\"fields\"][\"input\"]},\n",
    "    ]\n",
    "\n",
    "    response = client.chat.completions.create(\n",
    "      model=\"meta-llama/Llama-3.3-70B-Instruct-Turbo\",\n",
    "      messages=messages,\n",
    "      temperature=0\n",
    "    )\n",
    "\n",
    "    prediction = response.choices[0].message.content\n",
    "    result_optimized.append(evaluate(entry[\"answer\"], prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dd5b9d6-3d17-494e-89ee-d25c144622fa",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": [
    "result_optimized[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fa27268-9e3c-477c-b7fc-9284c7df11ef",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": [
    "result_optimized[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10141053-db33-435e-812c-0e5549c638e8",
   "metadata": {
    "height": 79
   },
   "outputs": [],
   "source": [
    "float_keys = [k for k, v in result_original[0].items() if isinstance(v,\n",
    "                                                (int, float, bool))]\n",
    "{k: sum([e[k] for e in result_original])/len(result_original) for k in float_keys}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed502c37-21f9-4421-9705-cdea6c9759a8",
   "metadata": {
    "height": 45
   },
   "outputs": [],
   "source": [
    "{k: sum([e[k] for e in result_optimized])/len(result_optimized) for k in float_keys}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfe99719-9560-4ace-9717-56ee31eebdc2",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bae96c70-965d-4b8b-a63c-d8107f53284a",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62531e29-5e87-43e8-9173-2329dd8a046d",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f22af04-f412-4b7f-a248-11e9204c9d91",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa59b1b2-c569-452d-98c1-ccb4c2f4827d",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "057437d5-7e48-4cf6-a931-424f679e262e",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
