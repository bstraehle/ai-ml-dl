{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tool Calling Use Cases"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"background-color:#fff6e4; padding:15px; border-width:3px; border-color:#f5ecda; border-style:solid; border-radius:6px\"> ‚è≥ <b>Note <code>(Kernel Starting)</code>:</b> This notebook takes about 30 seconds to be ready to use. You may start and watch the video while you wait.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "height": 47
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get API keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "height": 48
   },
   "outputs": [],
   "source": [
    "from utils import get_tavily_api_key\n",
    "TAVILY_API_KEY = get_tavily_api_key()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "height": 65
   },
   "outputs": [],
   "source": [
    "from utils import llama31\n",
    "from utils import cprint\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"background-color:#fff6ff; padding:15px; border-width:3px; border-color:#efe6ef; border-style:solid; border-radius:6px\"> üíª &nbsp; <b>Access <code>requirements.txt</code> and <code>utils.py</code> files:</b> 1) click on the <em>\"File\"</em> option on the top menu of the notebook and then 2) click on <em>\"Open\"</em>. For more help, please see the <em>\"Appendix - Tips and Help\"</em> Lesson.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define tool system prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "height": 115
   },
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "current_date = datetime.now()\n",
    "formatted_date = current_date.strftime(\"%d %B %Y\")\n",
    "print(formatted_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "height": 149
   },
   "outputs": [],
   "source": [
    "tool_system_prompt = f\"\"\"<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
    "\n",
    "Environment: ipython\n",
    "Tools: brave_search, wolfram_alpha\n",
    "Cutting Knowledge Date: December 2023\n",
    "Today Date: {formatted_date}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The brave_search built-in tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "height": 115
   },
   "outputs": [],
   "source": [
    "prompt = tool_system_prompt + f\"\"\"<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
    "\n",
    "What is the current weather in Menlo Park, California?\n",
    "\n",
    "<|eot_id|><|start_header_id|>assistant<|end_header_id|>\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "height": 48
   },
   "outputs": [],
   "source": [
    "response = llama31(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "height": 115
   },
   "outputs": [],
   "source": [
    "no_tool_call_prompt = tool_system_prompt + f\"\"\"<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
    "\n",
    "What is the population of California?\n",
    "\n",
    "<|eot_id|><|start_header_id|>assistant<|end_header_id|>\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "height": 64
   },
   "outputs": [],
   "source": [
    "no_tool_call_response = llama31(no_tool_call_prompt)\n",
    "print(no_tool_call_response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calling the search API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "height": 115
   },
   "outputs": [],
   "source": [
    "from tavily import TavilyClient\n",
    "tavily_client = TavilyClient(api_key=TAVILY_API_KEY)\n",
    "\n",
    "result = tavily_client.search(\"current weather in Menlo Park, California\")\n",
    "cprint(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reprompting Llama with search tool response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "height": 64
   },
   "outputs": [],
   "source": [
    "search_result = result[\"results\"][0][\"content\"]\n",
    "print(search_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "height": 217
   },
   "outputs": [],
   "source": [
    "prompt = tool_system_prompt + f\"\"\"<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
    "What is the current weather in Menlo Park, California?\n",
    "\n",
    "<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
    "\n",
    "<|python_tag|>{response}<|eom_id|>\n",
    "<|start_header_id|>ipython<|end_header_id|>\n",
    "\n",
    "{search_result}<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
    "\"\"\"\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "height": 48
   },
   "outputs": [],
   "source": [
    "response = llama31(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using the higher-level message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "height": 116
   },
   "outputs": [],
   "source": [
    "system_prompt_content = f\"\"\"\n",
    "Environment: ipython\n",
    "Tools: brave_search, wolfram_alpha\n",
    "Cutting Knowledge Date: December 2023\n",
    "Today Date: {formatted_date}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "height": 98
   },
   "outputs": [],
   "source": [
    "messages = [\n",
    "    {\"role\": \"system\", \"content\":  system_prompt_content},\n",
    "    {\"role\": \"user\",   \"content\": \"What is the current weather in Menlo Park, California?\"}\n",
    "  ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "height": 48
   },
   "outputs": [],
   "source": [
    "response = llama31(messages)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "height": 132
   },
   "outputs": [],
   "source": [
    "messages = [\n",
    "    {\"role\": \"system\",     \"content\":  system_prompt_content},\n",
    "    {\"role\": \"user\",       \"content\": \"What is the current weather in Menlo Park, California?\"},\n",
    "    {\"role\": \"assistant\",  \"content\": response},\n",
    "    {\"role\": \"ipython\",    \"content\": search_result}\n",
    "  ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "height": 48
   },
   "outputs": [],
   "source": [
    "response = llama31(messages)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Wolfram Alpha tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "height": 47
   },
   "outputs": [],
   "source": [
    "math_problem = \"Can you help me solve this equation: x^3 - 2x^2 - x + 2 = 0?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "height": 98
   },
   "outputs": [],
   "source": [
    "messages = [\n",
    "    {\"role\": \"system\",  \"content\": system_prompt_content},\n",
    "    {\"role\": \"user\",    \"content\": math_problem}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "height": 48
   },
   "outputs": [],
   "source": [
    "response = llama31(messages)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calling the Wolfram Alpha tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "height": 81
   },
   "outputs": [],
   "source": [
    "from utils import wolfram_alpha\n",
    "tool_result = wolfram_alpha(\"solve x^3 - 2x^2 - x + 2 = 0\")\n",
    "print(tool_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking the result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "height": 149
   },
   "outputs": [],
   "source": [
    "from sympy import symbols, Eq, solve\n",
    "\n",
    "x = symbols('x')                           # Define the variable\n",
    "equation = Eq(x**3 - 2*x**2 - 1*x + 2, 0) # Define the equation\n",
    "solution = solve(equation, x)              # Solve the equation\n",
    "\n",
    "print(solution)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reprompting Llama with Wolfram Alpha tool response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "height": 132
   },
   "outputs": [],
   "source": [
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": system_prompt_content},\n",
    "    {\"role\": \"user\",      \"content\": math_problem},\n",
    "    {\"role\": \"assistant\", \"content\": response},\n",
    "    {\"role\": \"ipython\",   \"content\": tool_result}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "height": 48
   },
   "outputs": [],
   "source": [
    "response = llama31(messages)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The code interpreter built-in tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "height": 115
   },
   "outputs": [],
   "source": [
    "loan_question = (\n",
    "    \"How much is the monthly payment, total payment, \"\n",
    "    \"and total interest paid for a 30 year mortgage of $1M \"\n",
    "    \"at a fixed rate of 6% with a 20% down payment?\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "height": 98
   },
   "outputs": [],
   "source": [
    "messages = [\n",
    "    {\"role\": \"system\",     \"content\": system_prompt_content},\n",
    "    {\"role\": \"user\",       \"content\": loan_question},\n",
    "  ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "height": 48
   },
   "outputs": [],
   "source": [
    "response = llama31(messages)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate loan payments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "height": 200
   },
   "outputs": [],
   "source": [
    "from utils import calculate_loan\n",
    "monthly_payment, total_payment, total_interest_paid = calculate_loan(\n",
    "    loan_amount = 1000000, \n",
    "    annual_interest_rate = 0.06, \n",
    "    loan_term = 30, \n",
    "    down_payment = 200000)\n",
    "\n",
    "print(f\"Monthly payment: ${(monthly_payment)}\")\n",
    "print(f\"Total payment: ${(total_payment)}\")\n",
    "print(f\"Total interest paid: ${(total_interest_paid)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating the code in Java"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "height": 115
   },
   "outputs": [],
   "source": [
    "messages = [\n",
    "    {\"role\":    \"system\",     \n",
    "     \"content\": system_prompt_content + \"\\nGenerate the code in Java.\"},\n",
    "    {\"role\":    \"user\",       \"content\": loan_question},\n",
    "  ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "height": 48
   },
   "outputs": [],
   "source": [
    "response = llama31(messages)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reprompting Llama with Code Interpreter tool response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "height": 99
   },
   "outputs": [],
   "source": [
    "code_interpreter_tool_response=\"\"\"\n",
    "Monthly payment: $4796\n",
    "Total payment: $1726705\n",
    "Total interest paid: $926705\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "height": 132
   },
   "outputs": [],
   "source": [
    "messages = [\n",
    "    {\"role\": \"system\", \"content\":  system_prompt_content},\n",
    "    {\"role\": \"user\",      \"content\": loan_question},\n",
    "    {\"role\": \"assistant\", \"content\": response},\n",
    "    {\"role\": \"ipython\",   \"content\": code_interpreter_tool_response}\n",
    "  ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "height": 48
   },
   "outputs": [],
   "source": [
    "response = llama31(messages)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Llama 3.1 custom tool calling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "height": 149
   },
   "outputs": [],
   "source": [
    "from utils import trending_songs, get_boiling_point\n",
    "\n",
    "country = \"US\"\n",
    "top_num = 5\n",
    "top_songs = trending_songs(country, top_num)\n",
    "print(f\"Top {top_num} trending songs in {country}:\")\n",
    "print(top_songs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"background-color:#fff6ff; padding:15px; border-width:3px; border-color:#efe6ef; border-style:solid; border-radius:6px\"> üíª &nbsp; <b>Access <code>trending_songs()</code> in <code>utils.py</code> files:</b> 1) click on the <em>\"File\"</em> option on the top menu of the notebook and then 2) click on <em>\"Open\"</em>. For more help, please see the <em>\"Appendix - Tips and Help\"</em> Lesson.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prompt Llama 3.1 for custom tool call"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "height": 557
   },
   "outputs": [],
   "source": [
    "user_prompt = \"\"\"\n",
    "Answer the user's question by using the following functions if needed.\n",
    "If none of the functions can be used, please say so.\n",
    "Functions (in JSON format):\n",
    "{\n",
    "    \"type\": \"function\", \"function\": {\n",
    "        \"name\": \"get_boiling_point\",\n",
    "        \"description\": \"Get the boiling point of a liquid\",\n",
    "        \"parameters\": {\n",
    "            \"type\": \"object\", \"properties\": [\n",
    "                {\"liquid_name\": {\"type\": \"object\", \"description\": \"name of the liquid\"}},\n",
    "                {\"celsius\": {\"type\": \"object\", \"description\": \"whether to use celsius\"}}\n",
    "            ], \"required\": [\"liquid_name\"]\n",
    "        }\n",
    "    }\n",
    "}\n",
    "{\n",
    "    \"type\": \"function\", \"function\": {\n",
    "        \"name\": \"trending_songs\",\n",
    "        \"description\": \"Returns the trending songs on a Music site\",\n",
    "        \"parameters\": {\n",
    "            \"type\": \"object\", \"properties\": [\n",
    "                {\"country\": {\"type\": \"object\", \"description\": \"country to return trending songs for\"}},\n",
    "                {\"n\": {\"type\": \"object\", \"description\": \"The number of songs to return\"}}\n",
    "            ], \"required\": [\"country\"]\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "Question: Can you check the top 5 trending songs in US?\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "height": 167
   },
   "outputs": [],
   "source": [
    "messages = [\n",
    "    {\n",
    "      \"role\": \"system\", \"content\":  f\"\"\"\n",
    "Environment: ipython\n",
    "Cutting Knowledge Date: December 2023\n",
    "Today Date: {formatted_date}\n",
    "\"\"\"},\n",
    "    {\"role\": \"user\", \"content\": user_prompt}\n",
    "  ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "height": 48
   },
   "outputs": [],
   "source": [
    "result = llama31(messages,405)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calling the custom tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "height": 64
   },
   "outputs": [],
   "source": [
    "custom_tools = {\"trending_songs\": trending_songs,\n",
    "                \"get_boiling_point\": get_boiling_point}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "height": 98
   },
   "outputs": [],
   "source": [
    "res = json.loads(result)\n",
    "function_name = res['name']\n",
    "parameters = list(res['parameters'].values())\n",
    "function_name, parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "height": 64
   },
   "outputs": [],
   "source": [
    "tool_result = custom_tools[function_name](*parameters)\n",
    "tool_result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reprompting Llama with custom tool call result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "height": 217
   },
   "outputs": [],
   "source": [
    "messages = [\n",
    "    {\n",
    "      \"role\": \"system\", \"content\":  f\"\"\"\n",
    "Environment: ipython\n",
    "Cutting Knowledge Date: December 2023\n",
    "Today Date: {formatted_date}\n",
    "\"\"\"},\n",
    "    {\"role\": \"user\", \"content\": user_prompt},\n",
    "    {\"role\": \"assistant\", \"content\": result},\n",
    "    {\"role\": \"ipython\", \"content\": ','.join(tool_result)}\n",
    "  ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "height": 48
   },
   "outputs": [],
   "source": [
    "response = llama31(messages, 70)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "height": 31
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "height": 31
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "height": 31
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "height": 31
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "height": 31
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
