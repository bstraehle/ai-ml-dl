{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2c367d6f-7ef4-4db2-8bea-17781a3a351e",
   "metadata": {},
   "source": [
    "# Multimodal Use Case"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0eed11ca-1249-4c51-a773-b60c9fa0fa23",
   "metadata": {},
   "source": [
    "<p style=\"background-color:#fff6e4; padding:15px; border-width:3px; border-color:#f5ecda; border-style:solid; border-radius:6px\"> ‚è≥ <b>Note <code>(Kernel Starting)</code>:</b> This notebook takes about 30 seconds to be ready to use. You may start and watch the video while you wait.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbade2c6-5ada-41fe-808b-ee74e6adcc8e",
   "metadata": {
    "height": 47
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1f03559-9c4b-45b6-ae20-52dffa25f380",
   "metadata": {
    "height": 48
   },
   "outputs": [],
   "source": [
    "from utils import load_env\n",
    "load_env()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e085990-6ab7-4589-aad5-672e0f76a6f9",
   "metadata": {},
   "source": [
    "## Load helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76812cc6-a892-4d0a-919c-d5faa1714b9f",
   "metadata": {
    "height": 31
   },
   "outputs": [],
   "source": [
    "from utils import llama32"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1b6fa99-e3b7-44e5-8fe5-60af07541d23",
   "metadata": {},
   "source": [
    "<p style=\"background-color:#fff6ff; padding:15px; border-width:3px; border-color:#efe6ef; border-style:solid; border-radius:6px\"> üíª &nbsp; <b>Access <code>requirements.txt</code> and <code>utils.py</code> files:</b> 1) click on the <em>\"File\"</em> option on the top menu of the notebook and then 2) click on <em>\"Open\"</em>. For more help, please see the <em>\"Appendix - Tips and Help\"</em> Lesson.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc093916-1195-45c1-834f-21b33eb039eb",
   "metadata": {
    "height": 115
   },
   "outputs": [],
   "source": [
    "import base64\n",
    "\n",
    "def encode_image(image_path):\n",
    "  with open(image_path, \"rb\") as image_file:\n",
    "    return base64.b64encode(image_file.read()).decode('utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2eaa6b6-461b-4a80-b344-2149d5a9b1dd",
   "metadata": {
    "height": 319
   },
   "outputs": [],
   "source": [
    "def llama32pi(prompt, image_url, model_size=90):\n",
    "  messages = [\n",
    "    {\n",
    "      \"role\": \"user\",\n",
    "      \"content\": [\n",
    "        {\"type\": \"text\",\n",
    "          \"text\": prompt},\n",
    "        {\"type\": \"image_url\",\n",
    "          \"image_url\": {\n",
    "            \"url\": image_url}\n",
    "        }\n",
    "      ]\n",
    "    },\n",
    "  ]\n",
    "\n",
    "  result = llama32(messages, model_size)\n",
    "  return result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f1b67a0-a32d-488d-b76f-582190ddbd08",
   "metadata": {},
   "source": [
    "## OCR with receipts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad0c9596-904f-4d0d-abb2-2617a5caf0a8",
   "metadata": {
    "height": 65
   },
   "outputs": [],
   "source": [
    "from utils import disp_image\n",
    "for i in range(1, 4):\n",
    "  disp_image(f\"images/receipt-{i}.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee5d860c-4a2e-4402-8ec8-402c9b820e05",
   "metadata": {
    "height": 149
   },
   "outputs": [],
   "source": [
    "question = \"What's the total charge in the receipt?\"\n",
    "results = \"\"\n",
    "for i in range(1, 4):\n",
    "    base64_image = encode_image(f\"images/receipt-{i}.jpg\")\n",
    "    res = llama32pi(question, f\"data:image/jpeg;base64,{base64_image}\")\n",
    "    results = results + f\"{res}\\n\"\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ff3983a-d2e8-4272-a21c-ffb63d3a7d86",
   "metadata": {
    "height": 132
   },
   "outputs": [],
   "source": [
    "messages = [\n",
    "    {\"role\": \"user\",\n",
    "     \"content\": f\"\"\"What's the total charge of all the recipts below?\n",
    "{results}\"\"\"\n",
    "  }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c66669f6-ea61-4db5-8369-8b677ed7637f",
   "metadata": {
    "height": 48
   },
   "outputs": [],
   "source": [
    "response = llama32(messages)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6bb4d62-6bc5-464e-ae04-247530445360",
   "metadata": {},
   "source": [
    "## Handling multiple images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21c3b1b2-4628-4830-8802-175c357ced12",
   "metadata": {
    "height": 166
   },
   "outputs": [],
   "source": [
    "from utils import merge_images\n",
    "import matplotlib.pyplot as plt\n",
    "merged_image = merge_images(\"images/receipt-1.jpg\",\n",
    "                            \"images/receipt-2.jpg\",\n",
    "                            \"images/receipt-3.jpg\")\n",
    "plt.imshow(merged_image)\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b19de0e1-b131-4ce4-a3af-1ca7c7c09daa",
   "metadata": {
    "height": 48
   },
   "outputs": [],
   "source": [
    "from utils import resize_image\n",
    "resized_img = resize_image(merged_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ff3a5ac-ffbb-4f6d-9b33-d1b2651c6472",
   "metadata": {
    "height": 115
   },
   "outputs": [],
   "source": [
    "base64_image = encode_image(\"images/resized_image.jpg\")\n",
    "question = \"What's the total charge of all the recipts below?\"\n",
    "result = llama32pi(question,\n",
    "                      f\"data:image/jpeg;base64,{base64_image}\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "719c5c75-ddcd-4d08-a7db-d54e748c3a7f",
   "metadata": {},
   "source": [
    "## Choosing the right drink"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b93e2f4-d919-48fd-aa48-8ea714ec0cb5",
   "metadata": {
    "height": 31
   },
   "outputs": [],
   "source": [
    "disp_image(\"images/drinks.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25aaf261-6137-41ed-815c-55d3c359acf5",
   "metadata": {
    "height": 47
   },
   "outputs": [],
   "source": [
    "question = \"I am on a diet. Which drink should I drink?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90ef55a9-e0dc-4083-b780-72a05fd815f6",
   "metadata": {
    "height": 81
   },
   "outputs": [],
   "source": [
    "base64_image = encode_image(\"images/drinks.png\")\n",
    "result = llama32pi(question, f\"data:image/png;base64,{base64_image}\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "026b1144-55a2-4fbd-b367-c8bdfdb45af6",
   "metadata": {
    "height": 98
   },
   "outputs": [],
   "source": [
    "question = (\"Generete nurtrition facts of the two drinks \" \n",
    "            \"in JSON format for easy comparison.\")\n",
    "result = llama32pi(question, f\"data:image/png;base64,{base64_image}\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ea78434-cfa6-4747-928c-8738078d4d48",
   "metadata": {},
   "source": [
    "## Understanding Llama MM model with code implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14900655-de22-4b29-97c9-45b6ff840485",
   "metadata": {
    "height": 31
   },
   "outputs": [],
   "source": [
    "disp_image(\"images/llama32mm.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "456c27b2-b80a-4a12-bdea-1485566d593b",
   "metadata": {
    "height": 132
   },
   "outputs": [],
   "source": [
    "question = (\"I see this diagram in the Llama 3 paper. \"\n",
    "            \"Summarize the flow in text and then return a \"\n",
    "            \"python script that implements the flow.\")\n",
    "base64_image = encode_image(\"images/llama32mm.png\")\n",
    "result = llama32pi(question, f\"data:image/png;base64,{base64_image}\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cf566eb-2ec3-493b-a326-458d574d7999",
   "metadata": {},
   "source": [
    "## Llama 3.1 70B Instruct model speed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "065bf3b0-2cfd-4380-b927-f8cd4c755a22",
   "metadata": {
    "height": 31
   },
   "outputs": [],
   "source": [
    "disp_image(\"images/llama31speed.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e638704f-6c5b-4fc5-8436-3e6253950a6c",
   "metadata": {
    "height": 98
   },
   "outputs": [],
   "source": [
    "question = \"Convert the chart to an HTML table.\"\n",
    "base64_image = encode_image(\"images/llama31speed.png\")\n",
    "result = llama32pi(question, f\"data:image/png;base64,{base64_image}\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b062ad4-d93c-4a9a-8977-6591c30b6492",
   "metadata": {
    "height": 81
   },
   "outputs": [],
   "source": [
    "from IPython.display import HTML\n",
    "minified_html_table = \"<table><thead><tr><th>Model</th><th>Output Tokens per Second</th></tr></thead><tbody><tr><td>Llama 2 1.5B</td><td>217</td></tr><tr><td>Google's PaLM 2 540B</td><td>214</td></tr><tr><td>Google's PaLM 2 540B</td><td>163</td></tr><tr><td>Meta's LLaMA 2 70B</td><td>133</td></tr><tr><td>Meta's LLaMA 2 70B</td><td>129</td></tr><tr><td>Google's T5 3.5B</td><td>123</td></tr><tr><td>OPT-6B</td><td>111</td></tr><tr><td>OPT-6B</td><td>75</td></tr><tr><td>ChatGPT-3.5</td><td>64</td></tr><tr><td>Google's T5 3.5B</td><td>62</td></tr><tr><td>Google's T5 3.5B</td><td>61</td></tr><tr><td>Meta's LLaMA 2 7B</td><td>68</td></tr><tr><td>Meta's LLaMA 2 7B</td><td>38</td></tr><tr><td>Meta's LLaMA 2 7B</td><td>38</td></tr><tr><td>Meta's LLaMA 2 7B</td><td>25</td></tr></tbody></table>\"\n",
    "HTML(minified_html_table)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c831694-ea1f-46d5-8c82-a06f6860231b",
   "metadata": {},
   "source": [
    "## Know your fridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98d71078-863f-45cc-bc12-6e3dda7ee391",
   "metadata": {
    "height": 31
   },
   "outputs": [],
   "source": [
    "disp_image(\"images/fridge-3.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbf3e606-b579-4a29-9f6f-d0308b5e39ab",
   "metadata": {
    "height": 115
   },
   "outputs": [],
   "source": [
    "question = (\"What're in the fridge? What kind of food can be made? Give \"\n",
    "            \"me 2 examples, based on only the ingredients in the fridge.\")\n",
    "base64_image = encode_image(\"images/fridge-3.jpg\")\n",
    "result = llama32pi(question, f\"data:image/jpg;base64,{base64_image}\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84aca14b-ed89-4c80-8b3a-f1c34cb11096",
   "metadata": {},
   "source": [
    "### Asking a follow up question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd0259a2-4312-4be0-9352-d2ec4d0ae7eb",
   "metadata": {
    "height": 217
   },
   "outputs": [],
   "source": [
    "new_question = \"is there banana in the fridge? where?\"\n",
    "messages = [\n",
    "  {\"role\": \"user\", \"content\": [\n",
    "      {\"type\": \"text\", \"text\": question},\n",
    "      {\"type\": \"image_url\", \"image_url\": {\"url\": f\"data:image/jpg;base64,{base64_image}\"}}\n",
    "  ]},\n",
    "  {\"role\": \"assistant\", \"content\": result},\n",
    "  {\"role\": \"user\", \"content\": new_question}\n",
    "]\n",
    "result = llama32(messages)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c9e7170-7766-49ce-a704-ac2f3134bb10",
   "metadata": {
    "height": 217
   },
   "outputs": [],
   "source": [
    "def llama32repi(question, image_url, result, new_question, model_size=90):\n",
    "    messages = [\n",
    "      {\"role\": \"user\", \"content\": [\n",
    "          {\"type\": \"text\", \"text\": question},\n",
    "          {\"type\": \"image_url\", \"image_url\": {\"url\": image_url}}\n",
    "      ]},\n",
    "      {\"role\": \"assistant\", \"content\": result},\n",
    "      {\"role\": \"user\", \"content\": new_question}\n",
    "    ]\n",
    "    result = llama32(messages, model_size)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f5af7e4-31cf-44b3-a4db-d693c2c74c75",
   "metadata": {},
   "source": [
    "## Interior Design Assistant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c32bfe61-226d-40f8-883a-106f1cc61af9",
   "metadata": {
    "height": 31
   },
   "outputs": [],
   "source": [
    "disp_image(\"images/001.jpeg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9da2201-d612-4f99-b522-26a84facc57d",
   "metadata": {
    "height": 132
   },
   "outputs": [],
   "source": [
    "question = (\"Describe the design, style, color, material and other \"\n",
    "            \"aspects of the fireplace in this photo. Then list all \"\n",
    "            \"the objects in the photo.\")\n",
    "base64_image = encode_image(\"images/001.jpeg\")\n",
    "result = llama32pi(question, f\"data:image/jpeg;base64,{base64_image}\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89e6c856-e100-40d2-95e5-8dbdb1f98a27",
   "metadata": {
    "height": 98
   },
   "outputs": [],
   "source": [
    "new_question = (\"How many balls and vases are there? Which one is closer \"\n",
    "                \"to the fireplace: the balls or the vases?\")\n",
    "res = llama32repi(question, f\"data:image/jpeg;base64,{base64_image}\", result, new_question)\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25f8e2ec-b270-49a7-9a3c-2be5323b0803",
   "metadata": {
    "height": 31
   },
   "outputs": [],
   "source": [
    "disp_image(\"images/001.jpeg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72f95e3b-1283-490a-a8f4-31bfeef589a4",
   "metadata": {},
   "source": [
    "## Math grader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b385fb22-c0a7-43e2-88a5-d15a2d99c3d6",
   "metadata": {
    "height": 31
   },
   "outputs": [],
   "source": [
    "disp_image(\"images/math_hw3.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82164e62-c05c-49f1-a3ef-abaa112b482d",
   "metadata": {
    "height": 149
   },
   "outputs": [],
   "source": [
    "prompt = (\"Check carefully each answer in a kid's math homework, first \"\n",
    "          \"do the calculation, then compare the result with the kid's \"\n",
    "          \"answer, mark correct or incorrect for each answer, and finally\"\n",
    "          \" return a total score based on all the problems answered.\")\n",
    "base64_image = encode_image(\"images/math_hw3.jpg\")\n",
    "result = llama32pi(prompt, f\"data:image/jpg;base64,{base64_image}\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11ffe21a-79e0-4132-a938-b75dcf0f0966",
   "metadata": {},
   "source": [
    "## Tool calling with image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "926d6154-001a-4921-a7d3-4553b0cadc63",
   "metadata": {
    "height": 31
   },
   "outputs": [],
   "source": [
    "disp_image(\"images/golden_gate.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ead1d85-944d-45f3-9a65-e5d75a46c207",
   "metadata": {
    "height": 98
   },
   "outputs": [],
   "source": [
    "question = (\"Where is the location of the place shown in the picture?\")\n",
    "base64_image = encode_image(\"images/golden_gate.png\")\n",
    "result = llama32pi(question, f\"data:image/png;base64,{base64_image}\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1124a89c-f8b1-4752-8f06-5d8d1fd71caa",
   "metadata": {
    "height": 81
   },
   "outputs": [],
   "source": [
    "weather_question = (\"What is the current weather in the location \"\n",
    "                 \"mentioned in the text below: \\n\"  f\"{result}\")\n",
    "print(weather_question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cddf2706-4c17-4d6c-a15a-1306d00d43e8",
   "metadata": {
    "height": 319
   },
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "current_date = datetime.now()\n",
    "formatted_date = current_date.strftime(\"%d %B %Y\")\n",
    "\n",
    "messages = [\n",
    "    {\"role\": \"system\",\n",
    "     \"content\":  f\"\"\"\n",
    "Environment: ipython\n",
    "Tools: brave_search, wolfram_alpha\n",
    "Cutting Knowledge Date: December 2023\n",
    "Today Date: {formatted_date}\n",
    "\"\"\"},\n",
    "    {\"role\": \"user\",\n",
    "     \"content\": weather_question}\n",
    "  ]\n",
    "print(llama32(messages))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20bc1f8c-b2a0-4250-aac6-96f03cf342ba",
   "metadata": {
    "height": 31
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90689263-85a4-4a97-867d-6ea60455c297",
   "metadata": {
    "height": 31
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "219581fc-280d-42b2-bf09-40f11a41cc80",
   "metadata": {
    "height": 31
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4228c4d9-ede4-435e-b304-26d3b12ad51d",
   "metadata": {
    "height": 31
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "544f006d-9a8a-4107-98fc-a9d2394f0c2a",
   "metadata": {
    "height": 31
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
