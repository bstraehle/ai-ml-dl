{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lesson 2: Create a SQL Agent\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Note: You can access the `data` and `util` subdirectories used in the course. In Jupyter version 6, this is via the File>Open menu. In Jupyter version 7 this is in View> File Browser\n",
    "\n",
    "> Also note that as models and systems change, the output of the models may shift from the video content."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "height": 47
   },
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "_ = load_dotenv()   #load environmental variable LAMINI_API_KEY with key from .env file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": [
    "import lamini "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "height": 183
   },
   "outputs": [],
   "source": [
    "import logging\n",
    "import sqlite3\n",
    "import pandas as pd\n",
    "from util.get_schema import get_schema\n",
    "from util.make_llama_3_prompt import make_llama_3_prompt\n",
    "from util.setup_logging import setup_logging\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "engine = sqlite3.connect(\"./nba_roster.db\")\n",
    "setup_logging()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": [
    "llm = lamini.Lamini(model_name=\"meta-llama/Meta-Llama-3-8B-Instruct\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "height": 181
   },
   "outputs": [],
   "source": [
    "# Meta Llama 3 Instruct uses a prompt template, with special tags used to indicate the user query and system prompt. \n",
    "# You can find the documentation on this [model card](https://llama.meta.com/docs/model-cards-and-prompt-formats/meta-llama-3/#meta-llama-3-instruct).\n",
    "def make_llama_3_prompt(user, system=\"\"):\n",
    "    system_prompt = \"\"\n",
    "    if system != \"\":\n",
    "        system_prompt = (\n",
    "            f\"<|start_header_id|>system<|end_header_id|>\\n\\n{system}<|eot_id|>\"\n",
    "        )\n",
    "    return f\"<|begin_of_text|>{system_prompt}<|start_header_id|>user<|end_header_id|>\\n\\n{user}<|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\n\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "height": 217
   },
   "outputs": [],
   "source": [
    "def get_schema():\n",
    "    return \"\"\"\\\n",
    "0|Team|TEXT \n",
    "1|NAME|TEXT  \n",
    "2|Jersey|TEXT \n",
    "3|POS|TEXT\n",
    "4|AGE|INT \n",
    "5|HT|TEXT \n",
    "6|WT|TEXT \n",
    "7|COLLEGE|TEXT \n",
    "8|SALARY|TEXT eg. \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": [
    "user = \"\"\"Who is the highest paid NBA player?\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "height": 96
   },
   "outputs": [],
   "source": [
    "system = f\"\"\"You are an NBA analyst with 15 years of experience writing complex SQL queries. Consider the nba_roster table with the following schema:\n",
    "{get_schema()}\n",
    "\n",
    "Write a sqlite query to answer the following question. Follow instructions exactly\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": [
    "print(system)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": [
    "prompt = make_llama_3_prompt(user, system)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": [
    "print(llm.generate(prompt, max_new_tokens=200))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "height": 217
   },
   "outputs": [],
   "source": [
    "def get_updated_schema():\n",
    "    return \"\"\"\\\n",
    "0|Team|TEXT eg. \"Toronto Raptors\"\n",
    "1|NAME|TEXT eg. \"Otto Porter Jr.\"\n",
    "2|Jersey|TEXT eg. \"0\" and when null has a value \"NA\"\n",
    "3|POS|TEXT eg. \"PF\"\n",
    "4|AGE|INT eg. \"22\" in years\n",
    "5|HT|TEXT eg. `6' 7\"` or `6' 10\"`\n",
    "6|WT|TEXT eg. \"232 lbs\" \n",
    "7|COLLEGE|TEXT eg. \"Michigan\" and when null has a value \"--\"\n",
    "8|SALARY|TEXT eg. \"$9,945,830\" and when null has a value \"--\"\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "height": 96
   },
   "outputs": [],
   "source": [
    "system = f\"\"\"You are an NBA analyst with 15 years of experience writing complex SQL queries. Consider the nba_roster table with the following schema:\n",
    "{get_updated_schema()}\n",
    "\n",
    "Write a sqlite query to answer the following question. Follow instructions exactly\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": [
    "prompt = make_llama_3_prompt(user, system)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": [
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": [
    "print(llm.generate(prompt, max_new_tokens=200))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Structured Output\n",
    "\n",
    "We'd like to be able to get just SQL output so we don't have to parse the query from the model response. For this we can use structured output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": [
    "result = llm.generate(prompt, output_type={\"sqlite_query\": \"str\"}, max_new_tokens=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is great, now we can directly query with the output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": [
    "df = pd.read_sql(result['sqlite_query'], con=engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Diagnose Hallucinations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The **wrong** query looks like this:\n",
    "\n",
    "```sql\n",
    "SELECT NAME, SALARY\n",
    "FROM nba_roster\n",
    "WHERE salary != '--'\n",
    "ORDER BY CAST(SALARY AS REAL) DESC\n",
    "LIMIT 1;\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The **correct** query is:\n",
    "\n",
    "```sql\n",
    "SELECT salary, name \n",
    "FROM nba_roster\n",
    "WHERE salary != '--'\n",
    "ORDER BY CAST(REPLACE(REPLACE(salary, '$', ''), ',','') AS INTEGER) DESC\n",
    "LIMIT 1;\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "height": 132
   },
   "outputs": [],
   "source": [
    "query=\"\"\"SELECT salary, name \n",
    "FROM nba_roster \n",
    "WHERE salary != '--' \n",
    "ORDER BY CAST(REPLACE(REPLACE(salary, '$', ''), ',','') AS INTEGER) DESC \n",
    "LIMIT 1;\"\"\"\n",
    "df = pd.read_sql(query, con=engine)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
