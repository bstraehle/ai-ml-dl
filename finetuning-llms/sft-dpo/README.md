Supervised Fine-Tuning (SFT) and Direct Preference Optimization (DPO)  

https://www.youtube.com/watch?v=QXVCqtAZAn4  

https://docs.google.com/presentation/d/1S8ao40-CdclRU0D2D9FdyN5x8fZL1Iv5/edit  

https://github.com/huggingface/alignment-handbook  

Google Colab:  

<a href="https://colab.research.google.com/drive/1WNSVtM82oknmzL1QrJlNu--yNaWbp6o9">Supervised fine-tuning (SFT) of an LLM  

<a href="https://colab.research.google.com/drive/1mWiOFBy3zY6OdINEvHN9EPoQ_VIvfFKw">Human preference fine-tuning using direct preference optimization (DPO) of an LLM</a>  
