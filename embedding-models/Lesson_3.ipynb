{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "497db21d-4e08-42a7-9258-90fecced929f",
   "metadata": {},
   "source": [
    "# L3: Token vs. Sentence Embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8f1436f-bc79-49e9-bef9-e500f553d0d3",
   "metadata": {},
   "source": [
    "<p style=\"background-color:#fff6e4; padding:15px; border-width:3px; border-color:#f5ecda; border-style:solid; border-radius:6px\"> ‚è≥ <b>Note <code>(Kernel Starting)</code>:</b> This notebook takes about 30 seconds to be ready to use. You may start and watch the video while you wait.</p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "372ca766-d5c2-409e-9385-1c1b2b775f86",
   "metadata": {
    "height": 64
   },
   "outputs": [],
   "source": [
    "# Warning control\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23226224-1ca8-4ab3-b8b6-ffd560b205e4",
   "metadata": {
    "height": 149
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import scipy\n",
    "\n",
    "from transformers import BertModel, BertTokenizer\n",
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06f6eb04-2dd2-4fc7-870f-6ce4a64b3d8c",
   "metadata": {},
   "source": [
    "<p style=\"background-color:#fff6ff; padding:15px; border-width:3px; border-color:#efe6ef; border-style:solid; border-radius:6px\"> üíª &nbsp; <b>Access <code>requirements.txt</code> file:</b> To access <code>requirements.txt</code> for this notebook, 1) click on the <em>\"File\"</em> option on the top menu of the notebook and then 2) click on <em>\"Open\"</em>. For more help, please see the <em>\"Appendix - Tips and Help\"</em> Lesson.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49d6f379-cf3c-44be-ba5a-5854e6970f09",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37949be5-9ee4-4b29-ba46-df28a0c5d792",
   "metadata": {
    "height": 336
   },
   "outputs": [],
   "source": [
    "model_name = \"./models/bert-base-uncased\"\n",
    "tokenizer = BertTokenizer.from_pretrained(model_name)\n",
    "model = BertModel.from_pretrained(model_name)\n",
    "\n",
    "def get_sentence_embedding(sentence):\n",
    "    encoded_input = tokenizer(sentence, padding=True, truncation=True, return_tensors='pt')\n",
    "    attention_mask = encoded_input['attention_mask']   # to indicate which tokens are valid and which are padding\n",
    "    \n",
    "    # Get the model output (without the specific classification head)\n",
    "    with torch.no_grad():\n",
    "        output = model(**encoded_input)\n",
    "\n",
    "    token_embeddings = output.last_hidden_state\n",
    "    input_mask_expanded = attention_mask.unsqueeze(-1).expand(token_embeddings.size()).float()\n",
    "\n",
    "    # mean pooling operation, considering the BERT input_mask and padding\n",
    "    sentence_embedding = torch.sum(token_embeddings * input_mask_expanded, 1) / torch.clamp(input_mask_expanded.sum(1), min=1e-9)\n",
    "    \n",
    "    return sentence_embedding.flatten().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23055d3e-3403-44bf-b7bf-997b94c0746a",
   "metadata": {
    "height": 115
   },
   "outputs": [],
   "source": [
    "def cosine_similarity_matrix(features):\n",
    "    norms = np.linalg.norm(features, axis=1, keepdims=True)\n",
    "    normalized_features = features / norms\n",
    "    similarity_matrix = np.inner(normalized_features, normalized_features)\n",
    "    rounded_similarity_matrix = np.round(similarity_matrix, 4)\n",
    "    return rounded_similarity_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "916a47b2-ece3-4719-a8bb-162f3a1fd33d",
   "metadata": {
    "height": 149
   },
   "outputs": [],
   "source": [
    "# Helper function to plot similarity matrix\n",
    "def plot_similarity(labels, features, rotation):\n",
    "    sim = cosine_similarity_matrix(features)\n",
    "    sns.set_theme(font_scale=1.2)\n",
    "    g = sns.heatmap(sim, xticklabels=labels, yticklabels=labels, vmin=0, vmax=1, cmap=\"YlOrRd\")\n",
    "    g.set_xticklabels(labels, rotation=rotation)\n",
    "    g.set_title(\"Semantic Textual Similarity\")\n",
    "    return g"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ac92833-0cfb-4641-b17a-b794cf0fb0e4",
   "metadata": {},
   "source": [
    "## Token Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf89b540-550a-47cb-a4a5-502d6544d949",
   "metadata": {
    "height": 353
   },
   "outputs": [],
   "source": [
    "messages = [\n",
    "    # Smartphones\n",
    "    \"I like my phone\",\n",
    "    \"My phone is not good.\",\n",
    "    \"Your cellphone looks great.\",\n",
    "\n",
    "    # Weather\n",
    "    \"Will it snow tomorrow?\",\n",
    "    \"Recently a lot of hurricanes have hit the US\",\n",
    "    \"Global warming is real\",\n",
    "\n",
    "    # Food and health\n",
    "    \"An apple a day, keeps the doctors away\",\n",
    "    \"Eating strawberries is healthy\",\n",
    "    \"Is paleo better than keto?\",\n",
    "\n",
    "    # Asking about age\n",
    "    \"How old are you?\",\n",
    "    \"what is your age?\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83bc91c4-fe9f-44d7-8735-c554ec3c4bfd",
   "metadata": {
    "height": 115
   },
   "outputs": [],
   "source": [
    "embeddings = []\n",
    "for t in messages:\n",
    "    emb = get_sentence_embedding(t)\n",
    "    embeddings.append(emb)\n",
    "\n",
    "plot_similarity(messages, embeddings, 90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3b3c8a2-1556-45cc-8db7-d5339c3e686b",
   "metadata": {
    "height": 98
   },
   "outputs": [],
   "source": [
    "sts_dataset = load_dataset(\"mteb/stsbenchmark-sts\")\n",
    "sts = pd.DataFrame({'sent1': sts_dataset['test']['sentence1'], \n",
    "                    'sent2': sts_dataset['test']['sentence2'],\n",
    "                    'score': [x/5 for x in sts_dataset['test']['score']]})\n",
    "sts.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04bc7be1-3f41-4f74-8c1f-dc53fdf466a5",
   "metadata": {},
   "source": [
    "<b>About the scores</b>: These scores are based on human evaluations and in the range 0 to 5 (see https://aclanthology.org/S17-2001.pdf table 1 for how they work). For example \"A woman is cutting onions\" vs \"A woman is cutting tofu\" can be considered by a human as in between 2-3 or so. The goal of STS is more to show another example where instead of just our intuition there is some kind of human labeled dataset, albeit it's not exactly a similarity in the sense of cosine but according to the rules of table 1 in the paper above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2fdb948-7ee0-46c6-8423-1bb6c1160bf7",
   "metadata": {
    "height": 200
   },
   "outputs": [],
   "source": [
    "def sim_two_sentences(s1, s2):\n",
    "    emb1 = get_sentence_embedding(s1)\n",
    "    emb2 = get_sentence_embedding(s2)\n",
    "    sim = cosine_similarity_matrix(np.vstack([emb1, emb2]))\n",
    "    return sim[0,1]\n",
    "\n",
    "n_examples = 50\n",
    "\n",
    "sts = sts.head(n_examples)\n",
    "sts['avg_bert_score'] = np.vectorize(sim_two_sentences) \\\n",
    "                                    (sts['sent1'], sts['sent2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70892259-2f28-4d46-addc-c063ba32a48b",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": [
    "sts.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9733e9a-2704-4bb1-b7ff-0d6c710d688a",
   "metadata": {
    "height": 47
   },
   "outputs": [],
   "source": [
    "pc = scipy.stats.pearsonr(sts['score'], sts['avg_bert_score'])\n",
    "print(f'Pearson correlation coefficient = {pc[0]}\\np-value = {pc[1]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3483184-dda2-4475-aab6-632d7c413987",
   "metadata": {},
   "source": [
    "## A better approach: SBERT and Dual Encoders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "449f1563-c1ec-497d-a736-aec65dc5efb1",
   "metadata": {
    "height": 149
   },
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "model = SentenceTransformer(\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "embeddings = []\n",
    "for t in messages:\n",
    "    emb = list(model.encode(t))\n",
    "    embeddings.append(emb)\n",
    "\n",
    "plot_similarity(messages, embeddings, 90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29c17cfc-02ad-4a02-99fc-da55da8c17ec",
   "metadata": {
    "height": 149
   },
   "outputs": [],
   "source": [
    "def sim_two_sentences(s1, s2):\n",
    "    emb1 = list(model.encode(s1))\n",
    "    emb2 = list(model.encode(s2))\n",
    "    sim = cosine_similarity_matrix(np.vstack([emb1, emb2]))\n",
    "    return sim[0,1]\n",
    "\n",
    "sts['mini_LM_score'] = np.vectorize(sim_two_sentences)(sts['sent1'], sts['sent2'])\n",
    "sts.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7a33357-6507-4ae9-a638-2de4af933c86",
   "metadata": {
    "height": 47
   },
   "outputs": [],
   "source": [
    "pc = scipy.stats.pearsonr(sts['score'], sts['mini_LM_score'])\n",
    "print(f'Pearson correlation coefficient = {pc[0]}\\np-value = {pc[1]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af5a9a16-016c-4240-9a3f-847c5a7d5624",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "789b0aa3-7a3b-4618-bc7e-14d18492a42d",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd7fd33c-c5f2-466a-b011-b6dc8495c2be",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80d282a2-0a68-4ef1-baab-15a1ec809741",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
