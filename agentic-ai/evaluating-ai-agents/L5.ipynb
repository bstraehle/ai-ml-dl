{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "25d40cab-6377-4609-a1c0-56ae790db763",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "# Lab 2: Tracing your Agent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff3410aa-5a1e-49d4-b42c-94a483503b5f",
   "metadata": {},
   "source": [
    "In this lab, you will collect traces from your agent code:\n",
    "- for OpenAI LLM calls, you will use OpenAIInstrumentor which automatically collects spans of type LLM containing the input and output of an LLM call;\n",
    "- for any other steps of your agent you want to track, you will manually instrument them by creating corresponding spans.\n",
    "\n",
    "When creating spans, you need to choose the [span kind](https://docs.arize.com/arize/llm-tracing/tracing/what-are-traces#span-kind). For this agent, you will create spans of types: \n",
    "- chain: to represent the starting point of a chain of steps or a link between different steps;\n",
    "- tool: to represent the call to an external tool;\n",
    "- agent: to represent the main span that encompasses calls to LLMs and Tools.\n",
    "\n",
    "Here's an example of how the spans might look like when you run the agent to respond to a user's query.\n",
    "<img src=\"images/spans_agent.png\" width=\"800\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de494e9a-2003-4ee5-8184-eae1ab603fff",
   "metadata": {},
   "source": [
    "You will create a span of type `agent` to represent the main span (response of an agent to a user's query). Within this span, you will create a span of a type `chain` to represent a single router call, and to indicate that there will be a series of steps taken under this router call. This includes the main llm call made by the router which will be automatically collected, and a span to of type `chain` to represent how the tools were handled. Under this chain, you wil create a span of type `tool` for each tool executed and under each tool, there might an llm call and maybe another chain of steps.\n",
    "\n",
    "This notebook contains the same code of the previous lab but with additional code that allows collecting traces from your code. Try to watch first the video to understand how the code is instrumented and then run all cells and at the end (**last code cell**), check out the **link to Phoenix UI** to examine the spans collected. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0730a734-601c-415e-8004-4d8846e769dc",
   "metadata": {},
   "source": [
    "## Importing necessary libraries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a8c367b-c83a-42d1-9431-223da62d033e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "import pandas as pd\n",
    "import json\n",
    "import duckdb\n",
    "from pydantic import BaseModel, Field\n",
    "from IPython.display import Markdown\n",
    "\n",
    "from helper import get_openai_api_key, get_phoenix_endpoint\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44c0c8b5-256e-4c8e-ac10-90a17e068c47",
   "metadata": {},
   "outputs": [],
   "source": [
    "import phoenix as px\n",
    "import os\n",
    "from phoenix.otel import register\n",
    "from openinference.instrumentation.openai import OpenAIInstrumentor\n",
    "from openinference.semconv.trace import SpanAttributes\n",
    "from opentelemetry.trace import Status, StatusCode\n",
    "from openinference.instrumentation import TracerProvider"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fda81584-ee79-46c3-810d-6626318900f7",
   "metadata": {},
   "source": [
    "<p style=\"background-color:#fff6ff; padding:15px; border-width:3px; border-color:#efe6ef; border-style:solid; border-radius:6px\"> ðŸ’» &nbsp; <b>Access <code>requirements.txt</code> and <code>helper.py</code> files:</b> 1) click on the <em>\"File\"</em> option on the top menu of the notebook and then 2) click on <em>\"Open\"</em>. For more help, please see the <em>\"Appendix â€“ Tips, Help, and Download\"</em> Lesson.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aba0f8aa-eb07-4da7-8a96-5db71a5b78b1",
   "metadata": {},
   "source": [
    "<p style=\"background-color:#f7fff8; padding:15px; border-width:3px; border-color:#e0f0e0; border-style:solid; border-radius:6px\"> ðŸš¨\n",
    "&nbsp; <b>Different Run Results:</b> The output generated by AI chat models can vary with each execution due to their dynamic, probabilistic nature. Your results might differ from those shown in the video.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "384dafee-d367-4d39-98c4-8ad711845cbe",
   "metadata": {},
   "source": [
    "## Initializing the OpenAI client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f6792c7-5246-4aeb-a683-9f8ac5b921a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize the OpenAI client\n",
    "openai_api_key = get_openai_api_key()\n",
    "client = OpenAI(api_key=openai_api_key)\n",
    "\n",
    "MODEL = \"gpt-4o-mini\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad06b543-93eb-4b4f-8ba8-59067cf000ed",
   "metadata": {},
   "source": [
    "# Phoenix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a91f275-e864-4be0-83d5-591c7ba2a9ce",
   "metadata": {},
   "source": [
    "Phoenix is an AI observability platform that you can use to visualize the traces collected from your code. The Phoenix server is already launched for you, and you are provided with its endpoint (address) so you can configure a TracerProvider to send traces to Phoenix.\n",
    "\n",
    "**Note**: You can launch a local version of Phoenix in your own local notebook environment using `session = px.launch_app()` (as shown [here](https://docs.arize.com/phoenix/deployment/environments#notebooks)). In this notebook, you don't need to launch the Phoenix server, it's already configured for you."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5401d4e-d784-4295-a28c-f632a2b642ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "PROJECT_NAME = \"tracing-agent\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "347486ef-8394-4fa9-88f0-cf4bcf3d6078",
   "metadata": {},
   "outputs": [],
   "source": [
    "tracer_provider = register(\n",
    "    project_name=PROJECT_NAME,\n",
    "    endpoint= get_phoenix_endpoint() + \"v1/traces\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cd5a765",
   "metadata": {},
   "source": [
    "**Note**: To check Phoenix UI, you can open the link provided in the last code cell. The link shown in the output of the previous cell includes this additional string \"v1/traces\" and represents where the traces will be collected not the UI. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b2b2024-1b99-45bf-97c0-5634fa59471f",
   "metadata": {},
   "source": [
    "Setup the OpenAIInsrumentor to automatically collect OpenAI LLM calls from your code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd684301-6e67-42c0-a247-4abf443f399a",
   "metadata": {},
   "outputs": [],
   "source": [
    "OpenAIInstrumentor().instrument(tracer_provider = tracer_provider)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3e55495-6fa6-4982-98f5-72247caf905c",
   "metadata": {},
   "source": [
    "Get the tracer (object that creates spans) from the tracer provider (object that provides/sends the collected traces to Phoenix). You will use the tracer object to create the chain, tool and agent spans."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53b81feb-dcc2-434a-939d-64f1cb3dc83c",
   "metadata": {},
   "outputs": [],
   "source": [
    "tracer = tracer_provider.get_tracer(__name__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b976279-fcb8-433d-a7e9-4b61e8e4a631",
   "metadata": {},
   "source": [
    "## Defining the tools"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90f98a21-d25c-4334-8604-2ab8c9d0e2af",
   "metadata": {},
   "source": [
    "### Tool 1: Database Lookup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16729638-bcbf-41d6-ad19-b03df8c6d437",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the path to the transactional data\n",
    "TRANSACTION_DATA_FILE_PATH = 'data/Store_Sales_Price_Elasticity_Promotions_Data.parquet'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "905be4f0-3be4-4832-ac63-8d46c7385935",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prompt template for step 2 of tool 1\n",
    "SQL_GENERATION_PROMPT = \"\"\"\n",
    "Generate an SQL query based on a prompt. Do not reply with anything besides the SQL query.\n",
    "The prompt is: {prompt}\n",
    "\n",
    "The available columns are: {columns}\n",
    "The table name is: {table_name}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3282aac-c4ca-4798-890b-53bf347b9e51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# code for step 2 of tool 1\n",
    "def generate_sql_query(prompt: str, columns: list, table_name: str) -> str:\n",
    "    \"\"\"Generate an SQL query based on a prompt\"\"\"\n",
    "    formatted_prompt = SQL_GENERATION_PROMPT.format(prompt=prompt, \n",
    "                                                    columns=columns, \n",
    "                                                    table_name=table_name)\n",
    "\n",
    "    response = client.chat.completions.create(\n",
    "        model=MODEL,\n",
    "        messages=[{\"role\": \"user\", \"content\": formatted_prompt}],\n",
    "    )\n",
    "    \n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bc361a6-1251-454b-bd22-819c5274ba77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# code for tool 1\n",
    "@tracer.tool()\n",
    "def lookup_sales_data(prompt: str) -> str:\n",
    "    \"\"\"Implementation of sales data lookup from parquet file using SQL\"\"\"\n",
    "    try:\n",
    "\n",
    "        # define the table name\n",
    "        table_name = \"sales\"\n",
    "        \n",
    "        # step 1: read the parquet file into a DuckDB table\n",
    "        df = pd.read_parquet(TRANSACTION_DATA_FILE_PATH)\n",
    "        duckdb.sql(f\"CREATE TABLE IF NOT EXISTS {table_name} AS SELECT * FROM df\")\n",
    "\n",
    "        # step 2: generate the SQL code\n",
    "        sql_query = generate_sql_query(prompt, df.columns, table_name)\n",
    "        # clean the response to make sure it only includes the SQL code\n",
    "        sql_query = sql_query.strip()\n",
    "        sql_query = sql_query.replace(\"```sql\", \"\").replace(\"```\", \"\")\n",
    "\n",
    "        with tracer.start_as_current_span(\n",
    "            \"execute_sql_query\", \n",
    "            openinference_span_kind=\"chain\"\n",
    "        ) as span:\n",
    "            span.set_input(sql_query)\n",
    "            # step 3: execute the SQL query\n",
    "            result = duckdb.sql(sql_query).df()\n",
    "            span.set_output(value=str(result))\n",
    "            span.set_status(StatusCode.OK)\n",
    "        \n",
    "        return result.to_string()\n",
    "    except Exception as e:\n",
    "        return f\"Error accessing data: {str(e)}\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3493199-ffcc-4027-8599-64638db0237f",
   "metadata": {},
   "source": [
    "### Tool 2: Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb9e108e-bf44-4c90-a5ee-af4a4597a77c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct prompt based on analysis type and data subset\n",
    "DATA_ANALYSIS_PROMPT = \"\"\"\n",
    "Analyze the following data: {data}\n",
    "Your job is to answer the following question: {prompt}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6f25872-1d6f-492a-9fbc-0f153d78e0a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# code for tool 2\n",
    "@tracer.tool()\n",
    "def analyze_sales_data(prompt: str, data: str) -> str:\n",
    "    \"\"\"Implementation of AI-powered sales data analysis\"\"\"\n",
    "    formatted_prompt = DATA_ANALYSIS_PROMPT.format(data=data, prompt=prompt)\n",
    "\n",
    "    response = client.chat.completions.create(\n",
    "        model=MODEL,\n",
    "        messages=[{\"role\": \"user\", \"content\": formatted_prompt}],\n",
    "    )\n",
    "    \n",
    "    analysis = response.choices[0].message.content\n",
    "    return analysis if analysis else \"No analysis could be generated\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f14a090-d5c9-4a3f-b92f-65932e143c91",
   "metadata": {},
   "source": [
    "### Tool 3: Data Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3691330-7300-46e0-8ff3-1d7712d4c292",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prompt template for step 1 of tool 3\n",
    "CHART_CONFIGURATION_PROMPT = \"\"\"\n",
    "Generate a chart configuration based on this data: {data}\n",
    "The goal is to show: {visualization_goal}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2a551ae-35e5-460e-9ae0-cd1e5c7f6550",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class defining the response format of step 1 of tool 3\n",
    "class VisualizationConfig(BaseModel):\n",
    "    chart_type: str = Field(..., description=\"Type of chart to generate\")\n",
    "    x_axis: str = Field(..., description=\"Name of the x-axis column\")\n",
    "    y_axis: str = Field(..., description=\"Name of the y-axis column\")\n",
    "    title: str = Field(..., description=\"Title of the chart\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e99edc6-a59e-4ef5-a05a-55501c2a4f54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# code for step 1 of tool 3\n",
    "@tracer.chain()\n",
    "def extract_chart_config(data: str, visualization_goal: str) -> dict:\n",
    "    \"\"\"Generate chart visualization configuration\n",
    "    \n",
    "    Args:\n",
    "        data: String containing the data to visualize\n",
    "        visualization_goal: Description of what the visualization should show\n",
    "        \n",
    "    Returns:\n",
    "        Dictionary containing line chart configuration\n",
    "    \"\"\"\n",
    "    formatted_prompt = CHART_CONFIGURATION_PROMPT.format(data=data, \n",
    "                                                         visualization_goal=visualization_goal)\n",
    "    \n",
    "    response = client.beta.chat.completions.parse(\n",
    "        model=MODEL,\n",
    "        messages=[{\"role\": \"user\", \"content\": formatted_prompt}],\n",
    "        response_format=VisualizationConfig,\n",
    "    )\n",
    "    \n",
    "    try:\n",
    "        # Extract axis and title info from response\n",
    "        content = response.choices[0].message.content\n",
    "        \n",
    "        # Return structured chart config\n",
    "        return {\n",
    "            \"chart_type\": content.chart_type,\n",
    "            \"x_axis\": content.x_axis,\n",
    "            \"y_axis\": content.y_axis,\n",
    "            \"title\": content.title,\n",
    "            \"data\": data\n",
    "        }\n",
    "    except Exception:\n",
    "        return {\n",
    "            \"chart_type\": \"line\", \n",
    "            \"x_axis\": \"date\",\n",
    "            \"y_axis\": \"value\",\n",
    "            \"title\": visualization_goal,\n",
    "            \"data\": data\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e99b0e1f-642e-429e-89c7-371d7045dda7",
   "metadata": {},
   "outputs": [],
   "source": [
    "CREATE_CHART_PROMPT = \"\"\"\n",
    "Write python code to create a chart based on the following configuration.\n",
    "Only return the code, no other text.\n",
    "config: {config}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce93df0f-fd43-4145-a829-78d53c6de2cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# code for step 2 of tool 3\n",
    "@tracer.chain()\n",
    "def create_chart(config: dict) -> str:\n",
    "    \"\"\"Create a chart based on the configuration\"\"\"\n",
    "    formatted_prompt = CREATE_CHART_PROMPT.format(config=config)\n",
    "    \n",
    "    response = client.chat.completions.create(\n",
    "        model=MODEL,\n",
    "        messages=[{\"role\": \"user\", \"content\": formatted_prompt}],\n",
    "    )\n",
    "    \n",
    "    code = response.choices[0].message.content\n",
    "    code = code.replace(\"```python\", \"\").replace(\"```\", \"\")\n",
    "    code = code.strip()\n",
    "    \n",
    "    return code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a907f1b0-e6d2-4649-9282-0cf8e48f5ffd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# code for tool 3\n",
    "@tracer.tool()\n",
    "def generate_visualization(data: str, visualization_goal: str) -> str:\n",
    "    \"\"\"Generate a visualization based on the data and goal\"\"\"\n",
    "    config = extract_chart_config(data, visualization_goal)\n",
    "    code = create_chart(config)\n",
    "    return code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b2f2911-986f-4490-a9a0-9ce4c9943a6e",
   "metadata": {},
   "source": [
    "## Tool Schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0d59f93-5af3-4ff3-aa0f-3e0d2162fd5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define tools/functions that can be called by the model\n",
    "tools = [\n",
    "    {\n",
    "        \"type\": \"function\",\n",
    "        \"function\": {\n",
    "            \"name\": \"lookup_sales_data\",\n",
    "            \"description\": \"Look up data from Store Sales Price Elasticity Promotions dataset\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"prompt\": {\"type\": \"string\", \"description\": \"The unchanged prompt that the user provided.\"}\n",
    "                },\n",
    "                \"required\": [\"prompt\"]\n",
    "            }\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"type\": \"function\",\n",
    "        \"function\": {\n",
    "            \"name\": \"analyze_sales_data\", \n",
    "            \"description\": \"Analyze sales data to extract insights\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"data\": {\"type\": \"string\", \"description\": \"The lookup_sales_data tool's output.\"},\n",
    "                    \"prompt\": {\"type\": \"string\", \"description\": \"The unchanged prompt that the user provided.\"}\n",
    "                },\n",
    "                \"required\": [\"data\", \"prompt\"]\n",
    "            }\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"type\": \"function\",\n",
    "        \"function\": {\n",
    "            \"name\": \"generate_visualization\",\n",
    "            \"description\": \"Generate Python code to create data visualizations\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\", \n",
    "                \"properties\": {\n",
    "                    \"data\": {\"type\": \"string\", \"description\": \"The lookup_sales_data tool's output.\"},\n",
    "                    \"visualization_goal\": {\"type\": \"string\", \"description\": \"The goal of the visualization.\"}\n",
    "                },\n",
    "                \"required\": [\"data\", \"visualization_goal\"]\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "]\n",
    "\n",
    "# Dictionary mapping function names to their implementations\n",
    "tool_implementations = {\n",
    "    \"lookup_sales_data\": lookup_sales_data,\n",
    "    \"analyze_sales_data\": analyze_sales_data, \n",
    "    \"generate_visualization\": generate_visualization\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d29a427c-3cdf-4921-9fc3-9056d5fa5e26",
   "metadata": {},
   "source": [
    "## Router Logic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62a94771-21cb-4fe9-a76f-8a90b843f866",
   "metadata": {},
   "outputs": [],
   "source": [
    "# code for executing the tools returned in the model's response\n",
    "@tracer.chain()\n",
    "def handle_tool_calls(tool_calls, messages):\n",
    "    \n",
    "    for tool_call in tool_calls:   \n",
    "        function = tool_implementations[tool_call.function.name]\n",
    "        function_args = json.loads(tool_call.function.arguments)\n",
    "        result = function(**function_args)\n",
    "        messages.append({\"role\": \"tool\", \n",
    "                         \"content\": result, \n",
    "                         \"tool_call_id\": tool_call.id})\n",
    "        \n",
    "    return messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d2288f8-0b3d-4719-b5c7-155a78c059ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "SYSTEM_PROMPT = \"\"\"\n",
    "You are a helpful assistant that can answer questions about the Store Sales Price Elasticity Promotions dataset.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a5e2f71-c008-45c3-955e-2abebfabb8a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_agent(messages):\n",
    "    print(\"Running agent with messages:\", messages)\n",
    "    if isinstance(messages, str):\n",
    "        messages = [{\"role\": \"user\", \"content\": messages}]\n",
    "    if not any(\n",
    "            isinstance(message, dict) and message.get(\"role\") == \"system\" for message in messages\n",
    "        ):\n",
    "            system_prompt = {\"role\": \"system\", \"content\": SYSTEM_PROMPT}\n",
    "            messages.append(system_prompt)\n",
    "\n",
    "    while True:\n",
    "        # Router Span\n",
    "        print(\"Starting router call span\")\n",
    "        with tracer.start_as_current_span(\n",
    "            \"router_call\", openinference_span_kind=\"chain\",\n",
    "        ) as span:\n",
    "            span.set_input(value=messages)\n",
    "            \n",
    "            response = client.chat.completions.create(\n",
    "                model=MODEL,\n",
    "                messages=messages,\n",
    "                tools=tools,\n",
    "            )\n",
    "            messages.append(response.choices[0].message.model_dump())\n",
    "            tool_calls = response.choices[0].message.tool_calls\n",
    "            print(\"Received response with tool calls:\", bool(tool_calls))\n",
    "            span.set_status(StatusCode.OK)\n",
    "    \n",
    "            if tool_calls:\n",
    "                print(\"Starting tool calls span\")\n",
    "                messages = handle_tool_calls(tool_calls, messages)\n",
    "                span.set_output(value=tool_calls)\n",
    "            else:\n",
    "                print(\"No tool calls, returning final response\")\n",
    "                span.set_output(value=response.choices[0].message.content)\n",
    "                return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41f43a1c-b6bf-45d8-9fb5-f677a0db350e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def start_main_span(messages):\n",
    "    print(\"Starting main span with messages:\", messages)\n",
    "    \n",
    "    with tracer.start_as_current_span(\n",
    "        \"AgentRun\", openinference_span_kind=\"agent\"\n",
    "    ) as span:\n",
    "        span.set_input(value=messages)\n",
    "        ret = run_agent(messages)\n",
    "        print(\"Main span completed with return value:\", ret)\n",
    "        span.set_output(value=ret)\n",
    "        span.set_status(StatusCode.OK)\n",
    "        return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcc6d06c-34b2-46af-b97f-506db6b01204",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = start_main_span([{\"role\": \"user\", \n",
    "                           \"content\": \"Which stores did the best in 2021?\"}])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6eca7a9-f519-4a66-939e-7ca7ef2e09b9",
   "metadata": {},
   "source": [
    "## Link to Phoenix UI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02b3ea65-ba44-4ad3-a096-1d89cf55f374",
   "metadata": {},
   "source": [
    "After you run all code cells, you can open this link to check out the Phoenix UI and observe the collected spans.\n",
    "\n",
    "**Note**:  Make sure that the notebook's kernel is running when checking the Phoenix UI. If the link does not open, it might be because the notebook has been open or inactive for a long time. In that case, make sure to refresh the browser, run all cells and then check this link. The link provided in this notebook is different from the one shown in the video."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c65d57e3-9f20-49f6-b4bf-2e71141d5fb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(get_phoenix_endpoint())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0cb8115-cb12-494f-a7a6-310c1a0241ba",
   "metadata": {},
   "source": [
    "<div style=\"background-color:#fff6ff; padding:13px; border-width:3px; border-color:#efe6ef; border-style:solid; border-radius:6px\">\n",
    "\n",
    "<p> â¬‡ &nbsp; <b>Download Notebooks:</b> 1) click on the <em>\"File\"</em> option on the top menu of the notebook and then 2) click on <em>\"Download as\"</em> and select <em>\"Notebook (.ipynb)\"</em>.</p>\n",
    "\n",
    "<p> ðŸ“’ &nbsp; For more help, please see the <em>\"Appendix â€“ Tips, Help, and Download\"</em> Lesson.</p>\n",
    "\n",
    "</div>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
